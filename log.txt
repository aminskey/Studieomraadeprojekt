epoch 0/15
training_loss: 2.3010737895965576
training_loss: 2.098118305206299
training_loss: 1.9747785329818726
training_loss: 1.851283311843872
training_loss: 1.6836574077606201
training_loss: 1.5662455558776855
training_loss: 1.5186479091644287
training_loss: 1.4307198524475098
training_loss: 1.4147933721542358
training_loss: 1.3760579824447632
training_loss: 1.2960554361343384
training_loss: 1.311279535293579
training_loss: 1.2789732217788696
training_loss: 1.298579216003418
training_loss: 1.2514969110488892
training_loss: 1.1518771648406982
training_loss: 1.2022300958633423
training_loss: 1.1281559467315674
training_loss: 1.132943868637085
training_loss: 1.1241562366485596
training_loss: 1.0411815643310547
training_loss: 1.0099785327911377
training_loss: 1.0465034246444702
training_loss: 1.0711901187896729
training_loss: 1.052485704421997
training_loss: 1.0205506086349487
training_loss: 0.9426082372665405
training_loss: 0.9430621266365051
training_loss: 0.9740626215934753
training_loss: 0.9929206967353821
training_loss: 1.0259499549865723
training_loss: 1.0268117189407349
training_loss: 0.9022873640060425
training_loss: 0.9763392806053162
training_loss: 0.9530895352363586
training_loss: 0.8771786093711853
training_loss: 0.8838639855384827
training_loss: 0.8692151308059692
training_loss: 0.8650494813919067
training_loss: 0.9387277364730835
training_loss: 0.9042201042175293
training_loss: 0.9108760356903076
training_loss: 0.7900747060775757
training_loss: 0.8543244004249573
training_loss: 0.889867901802063
training_loss: 0.8513209223747253
training_loss: 0.7935500741004944
training_loss: 0.8669114112854004
training_loss: 0.8456478118896484
training_loss: 0.8771659731864929
training_loss: 0.8912330269813538
training_loss: 0.897234320640564
training_loss: 0.837621808052063
training_loss: 0.8150450587272644
training_loss: 0.8921046853065491
training_loss: 0.7982398867607117
training_loss: 0.7832159399986267
training_loss: 0.9008159637451172
training_loss: 0.7875726222991943
training_loss: 0.8633995652198792
training_loss: 0.7976502180099487
training_loss: 0.8338370323181152
training_loss: 0.7244995832443237
training_loss: 0.7869356870651245
training_loss: 0.7726247906684875
training_loss: 0.8367294073104858
training_loss: 0.8046940565109253
training_loss: 0.7696413993835449
training_loss: 0.8140422105789185
training_loss: 0.7664827108383179
training_loss: 0.8648563623428345
training_loss: 0.781455397605896
training_loss: 0.7835167646408081
training_loss: 0.8542770147323608
training_loss: 0.7428123354911804
training_loss: 0.7314398288726807
training_loss: 0.7508695125579834
training_loss: 0.7543461918830872
training_loss: 0.7020676136016846
training_loss: 0.8149880766868591
training_loss: 0.7327653765678406
training_loss: 0.6831391453742981
training_loss: 0.7632168531417847
training_loss: 0.7534034848213196
training_loss: 0.7528412342071533
training_loss: 0.7628430128097534
training_loss: 0.8213826417922974
training_loss: 0.7172584533691406
training_loss: 0.6819665431976318
training_loss: 0.7424744963645935
training_loss: 0.7484603524208069
training_loss: 0.6912776231765747
training_loss: 0.8079866766929626
training_loss: 0.7443104982376099
training_loss: 0.7149215936660767
training_loss: 0.764653205871582
training_loss: 0.7277783155441284
training_loss: 0.7034738659858704
training_loss: 0.6791257262229919
training_loss: 0.7199662327766418
training_loss: 0.6593596339225769
training_loss: 0.6365474462509155
training_loss: 0.7889306545257568
training_loss: 0.6786291599273682
training_loss: 0.7318702340126038
training_loss: 0.7394773960113525
training_loss: 0.6875849962234497
training_loss: 0.7078685164451599
training_loss: 0.719390869140625
training_loss: 0.7055964469909668
training_loss: 0.72069251537323
training_loss: 0.7831281423568726
training_loss: 0.6861181259155273
training_loss: 0.6260288953781128
training_loss: 0.6798328757286072
training_loss: 0.6211035251617432
training_loss: 0.6670509576797485
training_loss: 0.629902184009552
training_loss: 0.7336614727973938
training_loss: 0.7181108593940735
training_loss: 0.6940595507621765
training_loss: 0.6789404153823853
training_loss: 0.6864262223243713
training_loss: 0.6600403785705566
training_loss: 0.6541796326637268
training_loss: 0.7067957520484924
training_loss: 0.6722644567489624
training_loss: 0.6747840046882629
training_loss: 0.7410722970962524
training_loss: 0.7016987800598145
training_loss: 0.7922446727752686
training_loss: 0.7616173028945923
training_loss: 0.6584955453872681
training_loss: 0.6790580153465271
training_loss: 0.644046425819397
training_loss: 0.650364875793457
training_loss: 0.7031702995300293
training_loss: 0.6590390801429749
training_loss: 0.7035340070724487
training_loss: 0.5775045156478882
training_loss: 0.7945756912231445
training_loss: 0.6657198667526245
training_loss: 0.7109643816947937
training_loss: 0.7218083143234253
training_loss: 0.6531510949134827
training_loss: 0.7595311999320984
training_loss: 0.6490525007247925
training_loss: 0.6800788044929504
training_loss: 0.6491162180900574
training_loss: 0.6422248482704163
training_loss: 0.7389520406723022
training_loss: 0.6208701133728027
training_loss: 0.6061974167823792
training_loss: 0.7297335863113403
training_loss: 0.6978819370269775
training_loss: 0.6788928508758545
training_loss: 0.628533124923706
training_loss: 0.672083854675293
training_loss: 0.6049649715423584
training_loss: 0.7142642140388489
training_loss: 0.6526092886924744
training_loss: 0.7071304321289062
training_loss: 0.6547544002532959
training_loss: 0.7062281966209412
training_loss: 0.6709247827529907
training_loss: 0.7235966324806213
training_loss: 0.6135089993476868
training_loss: 0.6128592491149902
training_loss: 0.6267511248588562
training_loss: 0.6810722947120667
training_loss: 0.5901762247085571
training_loss: 0.6823399662971497
training_loss: 0.5841497778892517
training_loss: 0.6698128581047058
training_loss: 0.630135715007782
training_loss: 0.7349948287010193
training_loss: 0.7065942883491516
training_loss: 0.6192231774330139
training_loss: 0.5636646151542664
training_loss: 0.6598214507102966
training_loss: 0.6025501489639282
training_loss: 0.6988720893859863
training_loss: 0.6481925845146179
training_loss: 0.6605356931686401
training_loss: 0.5978471636772156
training_loss: 0.5866901874542236
training_loss: 0.6540368795394897
training_loss: 0.5798205137252808
training_loss: 0.582457423210144
training_loss: 0.6599238514900208
training_loss: 0.6987646818161011
training_loss: 0.6288855671882629
training_loss: 0.5713045597076416
training_loss: 0.582619845867157
training_loss: 0.7041705846786499
training_loss: 0.5380686521530151
training_loss: 0.6066570281982422
training_loss: 0.8060148358345032
training_loss: 0.6488266587257385
training_loss: 0.5378441214561462
training_loss: 0.6202466487884521
training_loss: 0.666283905506134
training_loss: 0.6667059659957886
training_loss: 0.6745871305465698
training_loss: 0.5909301042556763
training_loss: 0.6633577346801758
training_loss: 0.5513837337493896
training_loss: 0.5984835624694824
training_loss: 0.6653763055801392
training_loss: 0.6725741028785706
training_loss: 0.6675345301628113
training_loss: 0.6534681916236877
training_loss: 0.5578857660293579
training_loss: 0.6755576133728027
training_loss: 0.5863112211227417
training_loss: 0.6158404350280762
training_loss: 0.5467638969421387
training_loss: 0.6244450807571411
training_loss: 0.5731163620948792
training_loss: 0.621036171913147
training_loss: 0.6769461631774902
training_loss: 0.7591509819030762
training_loss: 0.6058653593063354
training_loss: 0.5849570631980896
training_loss: 0.5264763832092285
training_loss: 0.5446345210075378
training_loss: 0.5900529623031616
training_loss: 0.5493229627609253
training_loss: 0.6059640645980835
training_loss: 0.5931464433670044
training_loss: 0.6100364923477173
training_loss: 0.5895532965660095
training_loss: 0.6071725487709045
training_loss: 0.6121295094490051
training_loss: 0.5721397399902344
validation_loss: 0.6216182112693787
validation_accuracy: 0.76953125
validation_loss: 0.5895119309425354
validation_accuracy: 0.78515625
validation_loss: 0.7403529286384583
validation_accuracy: 0.75390625
validation_loss: 0.6139988899230957
validation_accuracy: 0.78515625
validation_loss: 0.7061861753463745
validation_accuracy: 0.7734375
validation_loss: 0.6193864941596985
validation_accuracy: 0.76953125
validation_loss: 0.6277616024017334
validation_accuracy: 0.7890625
validation_loss: 0.6643783450126648
validation_accuracy: 0.78515625
validation_loss: 0.5828579068183899
validation_accuracy: 0.81640625
validation_loss: 0.6140256524085999
validation_accuracy: 0.80078125
validation_loss: 0.6368197798728943
validation_accuracy: 0.76953125
validation_loss: 0.8404771685600281
validation_accuracy: 0.7109375
validation_loss: 0.7852086424827576
validation_accuracy: 0.7265625
validation_loss: 0.745434045791626
validation_accuracy: 0.7421875
validation_loss: 0.6904507279396057
validation_accuracy: 0.77734375
validation_loss: 0.7600672841072083
validation_accuracy: 0.73046875
validation_loss: 0.6755886077880859
validation_accuracy: 0.765625
validation_loss: 0.4670935869216919
validation_accuracy: 0.84765625
validation_loss: 0.7030529975891113
validation_accuracy: 0.78125
validation_loss: 0.7184304594993591
validation_accuracy: 0.7734375
validation_loss: 0.6630045175552368
validation_accuracy: 0.76953125
validation_loss: 0.775443971157074
validation_accuracy: 0.74609375
validation_loss: 0.7233495116233826
validation_accuracy: 0.734375
validation_loss: 0.6294369697570801
validation_accuracy: 0.75390625
validation_loss: 0.6700055003166199
validation_accuracy: 0.75390625
validation_loss: 0.724330484867096
validation_accuracy: 0.72265625
validation_loss: 0.7243093252182007
validation_accuracy: 0.75390625
validation_loss: 0.6835773587226868
validation_accuracy: 0.76171875
validation_loss: 0.6881361603736877
validation_accuracy: 0.75390625
validation_loss: 0.6150265336036682
validation_accuracy: 0.76953125
validation_loss: 0.6952222585678101
validation_accuracy: 0.76171875
validation_loss: 0.7164714336395264
validation_accuracy: 0.74609375
validation_loss: 0.6389942169189453
validation_accuracy: 0.78125
validation_loss: 0.579110324382782
validation_accuracy: 0.80078125
validation_loss: 0.7380473017692566
validation_accuracy: 0.734375
validation_loss: 0.7203884720802307
validation_accuracy: 0.7421875
validation_loss: 0.6586369276046753
validation_accuracy: 0.75
validation_loss: 0.7177127599716187
validation_accuracy: 0.7734375
validation_loss: 0.6205998659133911
validation_accuracy: 0.78515625
validation_loss: 0.41651371121406555
validation_accuracy: 0.875
epoch 1/15
training_loss: 0.566261351108551
training_loss: 0.6109694838523865
training_loss: 0.6775815486907959
training_loss: 0.6006890535354614
training_loss: 0.6123695373535156
training_loss: 0.6390255093574524
training_loss: 0.5711934566497803
training_loss: 0.5497102737426758
training_loss: 0.6566780209541321
training_loss: 0.5889330506324768
training_loss: 0.6038557291030884
training_loss: 0.6192939281463623
training_loss: 0.6242519617080688
training_loss: 0.6498152613639832
training_loss: 0.6164895296096802
training_loss: 0.5687386393547058
training_loss: 0.6487942934036255
training_loss: 0.5806873440742493
training_loss: 0.5878857970237732
training_loss: 0.5458573698997498
training_loss: 0.6293614506721497
training_loss: 0.5633664131164551
training_loss: 0.604218065738678
training_loss: 0.6293675303459167
training_loss: 0.5763408541679382
training_loss: 0.6386587619781494
training_loss: 0.598712682723999
training_loss: 0.6530895233154297
training_loss: 0.6630288362503052
training_loss: 0.5479877591133118
training_loss: 0.5666948556900024
training_loss: 0.6660332083702087
training_loss: 0.6677218675613403
training_loss: 0.5360211133956909
training_loss: 0.6116538643836975
training_loss: 0.5849907398223877
training_loss: 0.5628716349601746
training_loss: 0.5213527083396912
training_loss: 0.5352029800415039
training_loss: 0.5775789022445679
training_loss: 0.6619748473167419
training_loss: 0.5703498721122742
training_loss: 0.6761608123779297
training_loss: 0.5619226098060608
training_loss: 0.6379466652870178
training_loss: 0.5751528143882751
training_loss: 0.6420861482620239
training_loss: 0.5687094330787659
training_loss: 0.5620648860931396
training_loss: 0.6047677993774414
training_loss: 0.598060667514801
training_loss: 0.5402028560638428
training_loss: 0.5229069590568542
training_loss: 0.6279984712600708
training_loss: 0.6138349771499634
training_loss: 0.5339691638946533
training_loss: 0.5834403038024902
training_loss: 0.5931089520454407
training_loss: 0.6609074473381042
training_loss: 0.5711418390274048
training_loss: 0.5907378196716309
training_loss: 0.61463862657547
training_loss: 0.5469905138015747
training_loss: 0.5488982796669006
training_loss: 0.5359545946121216
training_loss: 0.5194470882415771
training_loss: 0.5701801776885986
training_loss: 0.5867801904678345
training_loss: 0.5554699897766113
training_loss: 0.6062359809875488
training_loss: 0.5728869438171387
training_loss: 0.6372621059417725
training_loss: 0.5979527831077576
training_loss: 0.53810054063797
training_loss: 0.6809773445129395
training_loss: 0.5637224912643433
training_loss: 0.5915345549583435
training_loss: 0.5926238894462585
training_loss: 0.4610220193862915
training_loss: 0.49406862258911133
training_loss: 0.6384598612785339
training_loss: 0.5343339443206787
training_loss: 0.6506463885307312
training_loss: 0.5822357535362244
training_loss: 0.655323326587677
training_loss: 0.5617299675941467
training_loss: 0.5959102511405945
training_loss: 0.6028074026107788
training_loss: 0.5269827842712402
training_loss: 0.5471072793006897
training_loss: 0.5829216241836548
training_loss: 0.5751651525497437
training_loss: 0.5551456809043884
training_loss: 0.5572251081466675
training_loss: 0.6571863889694214
training_loss: 0.5876681208610535
training_loss: 0.5057156682014465
training_loss: 0.6629198789596558
training_loss: 0.5552366971969604
training_loss: 0.5394966006278992
training_loss: 0.5455172657966614
training_loss: 0.6230369806289673
training_loss: 0.6218066215515137
training_loss: 0.6051877737045288
training_loss: 0.5752291679382324
training_loss: 0.5003257393836975
training_loss: 0.5944408178329468
training_loss: 0.6222272515296936
training_loss: 0.5433565974235535
training_loss: 0.5939028859138489
training_loss: 0.55403733253479
training_loss: 0.6293573379516602
training_loss: 0.6376320123672485
training_loss: 0.5962879061698914
training_loss: 0.541897177696228
training_loss: 0.6304235458374023
training_loss: 0.5120118856430054
training_loss: 0.49597305059432983
training_loss: 0.5079759359359741
training_loss: 0.5431361198425293
training_loss: 0.5087085962295532
training_loss: 0.6047527194023132
training_loss: 0.6000655889511108
training_loss: 0.5727975964546204
training_loss: 0.5344231724739075
training_loss: 0.5708609819412231
training_loss: 0.5292801856994629
training_loss: 0.5796316266059875
training_loss: 0.5262567400932312
training_loss: 0.5307767987251282
training_loss: 0.5470772981643677
training_loss: 0.552833080291748
training_loss: 0.5867592096328735
training_loss: 0.49978986382484436
training_loss: 0.5562272667884827
training_loss: 0.5742528438568115
training_loss: 0.5682023763656616
training_loss: 0.5215374231338501
training_loss: 0.5684478878974915
training_loss: 0.6111112833023071
training_loss: 0.535668134689331
training_loss: 0.5602893233299255
training_loss: 0.7492545247077942
training_loss: 0.651167631149292
training_loss: 0.5508463978767395
training_loss: 0.591809868812561
training_loss: 0.5611799955368042
training_loss: 0.5578573942184448
training_loss: 0.6140289902687073
training_loss: 0.5552874207496643
training_loss: 0.5521625280380249
training_loss: 0.5474585890769958
training_loss: 0.5823913812637329
training_loss: 0.5853766202926636
training_loss: 0.5208144187927246
training_loss: 0.5349088311195374
training_loss: 0.6622791886329651
training_loss: 0.5757497549057007
training_loss: 0.4558158814907074
training_loss: 0.46110647916793823
training_loss: 0.502362072467804
training_loss: 0.5364865064620972
training_loss: 0.5101602077484131
training_loss: 0.5467497110366821
training_loss: 0.5372138619422913
training_loss: 0.6118512749671936
training_loss: 0.5534615516662598
training_loss: 0.5869701504707336
training_loss: 0.5754908919334412
training_loss: 0.6133514046669006
training_loss: 0.5836809277534485
training_loss: 0.4942229688167572
training_loss: 0.5438933372497559
training_loss: 0.6089527010917664
training_loss: 0.5560511350631714
training_loss: 0.6284916400909424
training_loss: 0.5297617316246033
training_loss: 0.550576388835907
training_loss: 0.38134270906448364
training_loss: 0.5343977212905884
training_loss: 0.4979422092437744
training_loss: 0.5521539449691772
training_loss: 0.5876340866088867
training_loss: 0.5804275274276733
training_loss: 0.5836679339408875
training_loss: 0.5199699997901917
training_loss: 0.5399031639099121
training_loss: 0.6231500506401062
training_loss: 0.49106866121292114
training_loss: 0.574769914150238
training_loss: 0.5850276350975037
training_loss: 0.5769201517105103
training_loss: 0.5138950347900391
training_loss: 0.5719510912895203
training_loss: 0.5085090398788452
training_loss: 0.6497071981430054
training_loss: 0.5396308302879333
training_loss: 0.49640241265296936
training_loss: 0.48929843306541443
training_loss: 0.5393489003181458
training_loss: 0.5215434432029724
training_loss: 0.551974892616272
training_loss: 0.6519864201545715
training_loss: 0.518297553062439
training_loss: 0.4811576306819916
training_loss: 0.48908933997154236
training_loss: 0.4951995015144348
training_loss: 0.5646719336509705
training_loss: 0.48408567905426025
training_loss: 0.5561420321464539
training_loss: 0.46037256717681885
training_loss: 0.5818641781806946
training_loss: 0.5294032096862793
training_loss: 0.5243344902992249
training_loss: 0.5155076384544373
training_loss: 0.5282038450241089
training_loss: 0.5069137215614319
training_loss: 0.49695444107055664
training_loss: 0.5699917674064636
training_loss: 0.5519951581954956
training_loss: 0.5843271017074585
training_loss: 0.5509047508239746
training_loss: 0.5184446573257446
training_loss: 0.5872596502304077
training_loss: 0.5273813605308533
training_loss: 0.5568705201148987
training_loss: 0.5790618062019348
training_loss: 0.6237983107566833
training_loss: 0.5899712443351746
training_loss: 0.5846365094184875
training_loss: 0.5475004315376282
training_loss: 0.540194034576416
training_loss: 0.6329522728919983
training_loss: 0.5579254031181335
training_loss: 0.6394188404083252
validation_loss: 0.5147600173950195
validation_accuracy: 0.82421875
validation_loss: 0.5128631591796875
validation_accuracy: 0.84375
validation_loss: 0.6266224980354309
validation_accuracy: 0.80078125
validation_loss: 0.5236750245094299
validation_accuracy: 0.83203125
validation_loss: 0.5882039070129395
validation_accuracy: 0.80859375
validation_loss: 0.5111567974090576
validation_accuracy: 0.8203125
validation_loss: 0.50581294298172
validation_accuracy: 0.85546875
validation_loss: 0.5618371963500977
validation_accuracy: 0.828125
validation_loss: 0.47268712520599365
validation_accuracy: 0.82421875
validation_loss: 0.5326749086380005
validation_accuracy: 0.8125
validation_loss: 0.5399860143661499
validation_accuracy: 0.80078125
validation_loss: 0.6996126174926758
validation_accuracy: 0.765625
validation_loss: 0.6929945945739746
validation_accuracy: 0.7890625
validation_loss: 0.6339405179023743
validation_accuracy: 0.765625
validation_loss: 0.5748163461685181
validation_accuracy: 0.8203125
validation_loss: 0.6436893939971924
validation_accuracy: 0.7890625
validation_loss: 0.5575733184814453
validation_accuracy: 0.796875
validation_loss: 0.3915129601955414
validation_accuracy: 0.88671875
validation_loss: 0.6102594137191772
validation_accuracy: 0.79296875
validation_loss: 0.6427649855613708
validation_accuracy: 0.765625
validation_loss: 0.6071218252182007
validation_accuracy: 0.80859375
validation_loss: 0.6677661538124084
validation_accuracy: 0.77734375
validation_loss: 0.5887829065322876
validation_accuracy: 0.7890625
validation_loss: 0.5298817157745361
validation_accuracy: 0.796875
validation_loss: 0.5278965830802917
validation_accuracy: 0.80859375
validation_loss: 0.6225009560585022
validation_accuracy: 0.77734375
validation_loss: 0.616658627986908
validation_accuracy: 0.796875
validation_loss: 0.550777018070221
validation_accuracy: 0.7734375
validation_loss: 0.5543456673622131
validation_accuracy: 0.8203125
validation_loss: 0.507033109664917
validation_accuracy: 0.8203125
validation_loss: 0.5717114210128784
validation_accuracy: 0.81640625
validation_loss: 0.6186560392379761
validation_accuracy: 0.78125
validation_loss: 0.5234309434890747
validation_accuracy: 0.81640625
validation_loss: 0.5125799179077148
validation_accuracy: 0.83984375
validation_loss: 0.63218092918396
validation_accuracy: 0.765625
validation_loss: 0.5801158547401428
validation_accuracy: 0.796875
validation_loss: 0.5377477407455444
validation_accuracy: 0.796875
validation_loss: 0.610851526260376
validation_accuracy: 0.81640625
validation_loss: 0.5244851112365723
validation_accuracy: 0.8203125
validation_loss: 0.33545467257499695
validation_accuracy: 0.9375
epoch 2/15
training_loss: 0.5761814117431641
training_loss: 0.5687187314033508
training_loss: 0.49882614612579346
training_loss: 0.5117629170417786
training_loss: 0.5496548414230347
training_loss: 0.49355006217956543
training_loss: 0.5811123251914978
training_loss: 0.5828490257263184
training_loss: 0.5464556217193604
training_loss: 0.6769590377807617
training_loss: 0.5881035327911377
training_loss: 0.5128008127212524
training_loss: 0.4826684892177582
training_loss: 0.5548298954963684
training_loss: 0.5061842799186707
training_loss: 0.4761573374271393
training_loss: 0.5593850612640381
training_loss: 0.5541540384292603
training_loss: 0.5293408036231995
training_loss: 0.5492891669273376
training_loss: 0.5374325513839722
training_loss: 0.5783219337463379
training_loss: 0.43051350116729736
training_loss: 0.5074417591094971
training_loss: 0.5027135014533997
training_loss: 0.6073358654975891
training_loss: 0.5785842537879944
training_loss: 0.4293014705181122
training_loss: 0.4895009994506836
training_loss: 0.5469518899917603
training_loss: 0.5452841520309448
training_loss: 0.42733630537986755
training_loss: 0.5532680749893188
training_loss: 0.4224497079849243
training_loss: 0.5326241850852966
training_loss: 0.5788117051124573
training_loss: 0.5347000360488892
training_loss: 0.44578370451927185
training_loss: 0.47955968976020813
training_loss: 0.5693507790565491
training_loss: 0.5563240647315979
training_loss: 0.6672858595848083
training_loss: 0.5816311240196228
training_loss: 0.4785146713256836
training_loss: 0.6090686321258545
training_loss: 0.5378261804580688
training_loss: 0.5218195915222168
training_loss: 0.5651727914810181
training_loss: 0.5494716763496399
training_loss: 0.5601503252983093
training_loss: 0.7291631698608398
training_loss: 0.587965190410614
training_loss: 0.4981631636619568
training_loss: 0.510934591293335
training_loss: 0.46812742948532104
training_loss: 0.5706073641777039
training_loss: 0.5641913414001465
training_loss: 0.5113277435302734
training_loss: 0.5709477066993713
training_loss: 0.4459070861339569
training_loss: 0.494071900844574
training_loss: 0.5535259246826172
training_loss: 0.5464975237846375
training_loss: 0.5313413739204407
training_loss: 0.581598699092865
training_loss: 0.5001512765884399
training_loss: 0.47326645255088806
training_loss: 0.436516135931015
training_loss: 0.4790874719619751
training_loss: 0.5689381957054138
training_loss: 0.504277765750885
training_loss: 0.5402138233184814
training_loss: 0.6023774743080139
training_loss: 0.6355825066566467
training_loss: 0.4929913282394409
training_loss: 0.5689080953598022
training_loss: 0.5097814798355103
training_loss: 0.563579797744751
training_loss: 0.5440978407859802
training_loss: 0.6036821603775024
training_loss: 0.49834081530570984
training_loss: 0.5117874145507812
training_loss: 0.6413695812225342
training_loss: 0.4928896725177765
training_loss: 0.6103517413139343
training_loss: 0.45327287912368774
training_loss: 0.4906598925590515
training_loss: 0.5363563299179077
training_loss: 0.504692792892456
training_loss: 0.48180562257766724
training_loss: 0.536045491695404
training_loss: 0.5488325357437134
training_loss: 0.4909464120864868
training_loss: 0.5021626949310303
training_loss: 0.519576907157898
training_loss: 0.5884137153625488
training_loss: 0.466042160987854
training_loss: 0.49928754568099976
training_loss: 0.5019383430480957
training_loss: 0.5287445187568665
training_loss: 0.5796679258346558
training_loss: 0.49607014656066895
training_loss: 0.5152131915092468
training_loss: 0.5165740847587585
training_loss: 0.5601885914802551
training_loss: 0.5311648845672607
training_loss: 0.5049889087677002
training_loss: 0.4154388904571533
training_loss: 0.4318854808807373
training_loss: 0.49471187591552734
training_loss: 0.5246049761772156
training_loss: 0.5757129192352295
training_loss: 0.5419906973838806
training_loss: 0.6586624383926392
training_loss: 0.4233207702636719
training_loss: 0.44679608941078186
training_loss: 0.5282325744628906
training_loss: 0.544083833694458
training_loss: 0.46624085307121277
training_loss: 0.5727538466453552
training_loss: 0.5538508892059326
training_loss: 0.5257649421691895
training_loss: 0.5077561736106873
training_loss: 0.5167188048362732
training_loss: 0.4750029146671295
training_loss: 0.6025983691215515
training_loss: 0.5210052728652954
training_loss: 0.5371214747428894
training_loss: 0.5045875906944275
training_loss: 0.46621274948120117
training_loss: 0.4995470345020294
training_loss: 0.5366820096969604
training_loss: 0.49155479669570923
training_loss: 0.43806350231170654
training_loss: 0.5300652384757996
training_loss: 0.44964489340782166
training_loss: 0.4362472891807556
training_loss: 0.5239880084991455
training_loss: 0.4504292905330658
training_loss: 0.4295176863670349
training_loss: 0.5461606383323669
training_loss: 0.5659512281417847
training_loss: 0.5663799047470093
training_loss: 0.48966923356056213
training_loss: 0.6367958784103394
training_loss: 0.5098510980606079
training_loss: 0.468757688999176
training_loss: 0.5534842610359192
training_loss: 0.5296503305435181
training_loss: 0.5531020760536194
training_loss: 0.4379611611366272
training_loss: 0.5331972241401672
training_loss: 0.6252709627151489
training_loss: 0.4981069564819336
training_loss: 0.4844207167625427
training_loss: 0.5655051469802856
training_loss: 0.5377101898193359
training_loss: 0.6073424220085144
training_loss: 0.5586087703704834
training_loss: 0.4538946747779846
training_loss: 0.5195751190185547
training_loss: 0.5015314817428589
training_loss: 0.5287364721298218
training_loss: 0.49772414565086365
training_loss: 0.4695602357387543
training_loss: 0.5277171730995178
training_loss: 0.532880425453186
training_loss: 0.5195997953414917
training_loss: 0.5400811433792114
training_loss: 0.5740945339202881
training_loss: 0.46771204471588135
training_loss: 0.5804057717323303
training_loss: 0.5944706797599792
training_loss: 0.5616568922996521
training_loss: 0.5174955725669861
training_loss: 0.5372591614723206
training_loss: 0.6136949062347412
training_loss: 0.47257450222969055
training_loss: 0.5190460681915283
training_loss: 0.6091156601905823
training_loss: 0.5097793340682983
training_loss: 0.49512800574302673
training_loss: 0.470836877822876
training_loss: 0.5199466943740845
training_loss: 0.44728004932403564
training_loss: 0.572698712348938
training_loss: 0.46779483556747437
training_loss: 0.5885213017463684
training_loss: 0.5037940740585327
training_loss: 0.5885721445083618
training_loss: 0.4641699194908142
training_loss: 0.5140246152877808
training_loss: 0.4704144597053528
training_loss: 0.5819301605224609
training_loss: 0.5141715407371521
training_loss: 0.5164155960083008
training_loss: 0.5168201327323914
training_loss: 0.4997240900993347
training_loss: 0.48251640796661377
training_loss: 0.5156917572021484
training_loss: 0.45706215500831604
training_loss: 0.5148637890815735
training_loss: 0.6916072964668274
training_loss: 0.5830655097961426
training_loss: 0.6157106161117554
training_loss: 0.47966551780700684
training_loss: 0.453039288520813
training_loss: 0.4510568082332611
training_loss: 0.4852495789527893
training_loss: 0.5353134870529175
training_loss: 0.5952652096748352
training_loss: 0.44059890508651733
training_loss: 0.4688415825366974
training_loss: 0.4764368236064911
training_loss: 0.539354145526886
training_loss: 0.4182218611240387
training_loss: 0.4505392611026764
training_loss: 0.5097677707672119
training_loss: 0.49162787199020386
training_loss: 0.546869695186615
training_loss: 0.5327845811843872
training_loss: 0.5444180965423584
training_loss: 0.469534695148468
training_loss: 0.5169433951377869
training_loss: 0.5031430721282959
training_loss: 0.5162184238433838
training_loss: 0.4900244474411011
training_loss: 0.49582090973854065
training_loss: 0.47535794973373413
training_loss: 0.503768801689148
training_loss: 0.6111831665039062
training_loss: 0.5778241157531738
training_loss: 0.516977071762085
training_loss: 0.5097049474716187
training_loss: 0.3407210409641266
validation_loss: 0.475966215133667
validation_accuracy: 0.83984375
validation_loss: 0.48137199878692627
validation_accuracy: 0.83203125
validation_loss: 0.6154471635818481
validation_accuracy: 0.8046875
validation_loss: 0.5201041102409363
validation_accuracy: 0.8125
validation_loss: 0.5686991214752197
validation_accuracy: 0.8046875
validation_loss: 0.4717756509780884
validation_accuracy: 0.83984375
validation_loss: 0.465219646692276
validation_accuracy: 0.87109375
validation_loss: 0.5358233451843262
validation_accuracy: 0.83203125
validation_loss: 0.44003644585609436
validation_accuracy: 0.828125
validation_loss: 0.5340655446052551
validation_accuracy: 0.8046875
validation_loss: 0.5407915115356445
validation_accuracy: 0.80859375
validation_loss: 0.6593095064163208
validation_accuracy: 0.78515625
validation_loss: 0.6620911955833435
validation_accuracy: 0.78125
validation_loss: 0.579475998878479
validation_accuracy: 0.8125
validation_loss: 0.5565221309661865
validation_accuracy: 0.8203125
validation_loss: 0.5810720324516296
validation_accuracy: 0.81640625
validation_loss: 0.521609902381897
validation_accuracy: 0.81640625
validation_loss: 0.3919511139392853
validation_accuracy: 0.8671875
validation_loss: 0.559809684753418
validation_accuracy: 0.80078125
validation_loss: 0.6111682653427124
validation_accuracy: 0.8046875
validation_loss: 0.6048005819320679
validation_accuracy: 0.83203125
validation_loss: 0.6499962210655212
validation_accuracy: 0.77734375
validation_loss: 0.540071427822113
validation_accuracy: 0.796875
validation_loss: 0.4831900894641876
validation_accuracy: 0.828125
validation_loss: 0.5012463331222534
validation_accuracy: 0.8046875
validation_loss: 0.6110190153121948
validation_accuracy: 0.79296875
validation_loss: 0.5928807258605957
validation_accuracy: 0.80859375
validation_loss: 0.4995400309562683
validation_accuracy: 0.80078125
validation_loss: 0.5283199548721313
validation_accuracy: 0.84375
validation_loss: 0.4898533821105957
validation_accuracy: 0.84375
validation_loss: 0.5396968722343445
validation_accuracy: 0.80859375
validation_loss: 0.5759205222129822
validation_accuracy: 0.78515625
validation_loss: 0.4906909465789795
validation_accuracy: 0.828125
validation_loss: 0.5117703080177307
validation_accuracy: 0.82421875
validation_loss: 0.611851692199707
validation_accuracy: 0.765625
validation_loss: 0.5488778352737427
validation_accuracy: 0.80078125
validation_loss: 0.4906385540962219
validation_accuracy: 0.83203125
validation_loss: 0.5675025582313538
validation_accuracy: 0.81640625
validation_loss: 0.4872570037841797
validation_accuracy: 0.8359375
validation_loss: 0.3472018837928772
validation_accuracy: 0.875
epoch 3/15
training_loss: 0.5907877087593079
training_loss: 0.4288994073867798
training_loss: 0.5168144106864929
training_loss: 0.5643617510795593
training_loss: 0.4239559471607208
training_loss: 0.4880673289299011
training_loss: 0.4716505706310272
training_loss: 0.47482937574386597
training_loss: 0.44738754630088806
training_loss: 0.5042198300361633
training_loss: 0.5191231966018677
training_loss: 0.46663033962249756
training_loss: 0.6514068841934204
training_loss: 0.43963098526000977
training_loss: 0.5007485151290894
training_loss: 0.5641785264015198
training_loss: 0.5390235185623169
training_loss: 0.5373736023902893
training_loss: 0.5051618814468384
training_loss: 0.5389795303344727
training_loss: 0.5179727673530579
training_loss: 0.4986076354980469
training_loss: 0.46909603476524353
training_loss: 0.6183491945266724
training_loss: 0.5187617540359497
training_loss: 0.5572644472122192
training_loss: 0.5571564435958862
training_loss: 0.538662850856781
training_loss: 0.582381010055542
training_loss: 0.463537335395813
training_loss: 0.49447035789489746
training_loss: 0.6037610769271851
training_loss: 0.48517075181007385
training_loss: 0.5065736174583435
training_loss: 0.47174686193466187
training_loss: 0.5214788913726807
training_loss: 0.41561827063560486
training_loss: 0.4748266339302063
training_loss: 0.5485766530036926
training_loss: 0.5931903123855591
training_loss: 0.4935328960418701
training_loss: 0.5095008611679077
training_loss: 0.4637320637702942
training_loss: 0.6505246162414551
training_loss: 0.5341179966926575
training_loss: 0.6093701124191284
training_loss: 0.5351175665855408
training_loss: 0.4938325881958008
training_loss: 0.47046297788619995
training_loss: 0.4360162913799286
training_loss: 0.40526896715164185
training_loss: 0.5159708261489868
training_loss: 0.5284358859062195
training_loss: 0.5144347548484802
training_loss: 0.5489630103111267
training_loss: 0.47310808300971985
training_loss: 0.5175911784172058
training_loss: 0.4954054355621338
training_loss: 0.47709769010543823
training_loss: 0.4849426746368408
training_loss: 0.49394282698631287
training_loss: 0.6074065566062927
training_loss: 0.46189451217651367
training_loss: 0.41668701171875
training_loss: 0.500799298286438
training_loss: 0.5273730158805847
training_loss: 0.4643726944923401
training_loss: 0.42011594772338867
training_loss: 0.4431171715259552
training_loss: 0.4277842044830322
training_loss: 0.5171303153038025
training_loss: 0.5251204967498779
training_loss: 0.5173630118370056
training_loss: 0.5205146670341492
training_loss: 0.5369990468025208
training_loss: 0.4826600253582001
training_loss: 0.5544661283493042
training_loss: 0.5876384377479553
training_loss: 0.5456703901290894
training_loss: 0.5753175020217896
training_loss: 0.44595810770988464
training_loss: 0.5199916362762451
training_loss: 0.47070610523223877
training_loss: 0.5409208536148071
training_loss: 0.50747150182724
training_loss: 0.4316943883895874
training_loss: 0.506534218788147
training_loss: 0.5726404786109924
training_loss: 0.450989305973053
training_loss: 0.43399670720100403
training_loss: 0.5303338766098022
training_loss: 0.5783416032791138
training_loss: 0.5159932374954224
training_loss: 0.41064372658729553
training_loss: 0.5032342672348022
training_loss: 0.5493472814559937
training_loss: 0.4824031591415405
training_loss: 0.42501598596572876
training_loss: 0.4842187166213989
training_loss: 0.5201877951622009
training_loss: 0.5183537602424622
training_loss: 0.4217498302459717
training_loss: 0.4656413793563843
training_loss: 0.441468209028244
training_loss: 0.4364925026893616
training_loss: 0.5792420506477356
training_loss: 0.5141660571098328
training_loss: 0.5625435709953308
training_loss: 0.47628527879714966
training_loss: 0.5327118039131165
training_loss: 0.4984237551689148
training_loss: 0.5473563075065613
training_loss: 0.5068032145500183
training_loss: 0.4911101460456848
training_loss: 0.4791320264339447
training_loss: 0.5194836854934692
training_loss: 0.4871199429035187
training_loss: 0.5748630166053772
training_loss: 0.5430998206138611
training_loss: 0.4583148956298828
training_loss: 0.5074716806411743
training_loss: 0.4457870423793793
training_loss: 0.5164260268211365
training_loss: 0.4886667728424072
training_loss: 0.45650896430015564
training_loss: 0.4785308241844177
training_loss: 0.5372973680496216
training_loss: 0.4217808246612549
training_loss: 0.4869600832462311
training_loss: 0.5225279331207275
training_loss: 0.42736777663230896
training_loss: 0.577951192855835
training_loss: 0.464236319065094
training_loss: 0.4986061155796051
training_loss: 0.5509634017944336
training_loss: 0.5449375510215759
training_loss: 0.49317026138305664
training_loss: 0.4855404496192932
training_loss: 0.5105588436126709
training_loss: 0.46658211946487427
training_loss: 0.5365872383117676
training_loss: 0.539742112159729
training_loss: 0.43275684118270874
training_loss: 0.6394593715667725
training_loss: 0.446259081363678
training_loss: 0.40838173031806946
training_loss: 0.42654404044151306
training_loss: 0.5704968571662903
training_loss: 0.49277588725090027
training_loss: 0.4723639488220215
training_loss: 0.45836305618286133
training_loss: 0.5705379247665405
training_loss: 0.4886245131492615
training_loss: 0.4872831702232361
training_loss: 0.44349536299705505
training_loss: 0.4313657879829407
training_loss: 0.5015432238578796
training_loss: 0.5414702296257019
training_loss: 0.4207990765571594
training_loss: 0.44861939549446106
training_loss: 0.49721601605415344
training_loss: 0.4809781610965729
training_loss: 0.5248550772666931
training_loss: 0.4970119297504425
training_loss: 0.5602719783782959
training_loss: 0.47125524282455444
training_loss: 0.4763079881668091
training_loss: 0.46761536598205566
training_loss: 0.41632765531539917
training_loss: 0.5066533088684082
training_loss: 0.484438419342041
training_loss: 0.4263785481452942
training_loss: 0.45953068137168884
training_loss: 0.4908439815044403
training_loss: 0.5105539560317993
training_loss: 0.4626852869987488
training_loss: 0.509085476398468
training_loss: 0.4322989284992218
training_loss: 0.50624018907547
training_loss: 0.4374733865261078
training_loss: 0.42176467180252075
training_loss: 0.43967968225479126
training_loss: 0.4593423008918762
training_loss: 0.4839197099208832
training_loss: 0.3999854028224945
training_loss: 0.47204434871673584
training_loss: 0.47198957204818726
training_loss: 0.47009965777397156
training_loss: 0.5216283798217773
training_loss: 0.4616936147212982
training_loss: 0.4823582172393799
training_loss: 0.4695316553115845
training_loss: 0.5052828192710876
training_loss: 0.4883614182472229
training_loss: 0.44407373666763306
training_loss: 0.5481653809547424
training_loss: 0.4993417263031006
training_loss: 0.5086707472801208
training_loss: 0.5392094850540161
training_loss: 0.5656764507293701
training_loss: 0.5031576752662659
training_loss: 0.5248972177505493
training_loss: 0.5419003367424011
training_loss: 0.56158846616745
training_loss: 0.46625030040740967
training_loss: 0.44607219099998474
training_loss: 0.4974917769432068
training_loss: 0.5095324516296387
training_loss: 0.5199571251869202
training_loss: 0.46104010939598083
training_loss: 0.6032131314277649
training_loss: 0.5458617210388184
training_loss: 0.44088053703308105
training_loss: 0.5656358003616333
training_loss: 0.5549876093864441
training_loss: 0.4941866397857666
training_loss: 0.5496702194213867
training_loss: 0.47932887077331543
training_loss: 0.5476540327072144
training_loss: 0.4574567675590515
training_loss: 0.45707231760025024
training_loss: 0.55699622631073
training_loss: 0.4913845658302307
training_loss: 0.4616014361381531
training_loss: 0.5266128778457642
training_loss: 0.5227629542350769
training_loss: 0.4927575886249542
training_loss: 0.47632336616516113
training_loss: 0.5130730867385864
training_loss: 0.5183125138282776
training_loss: 0.40281593799591064
training_loss: 0.5384669303894043
training_loss: 0.46050891280174255
training_loss: 0.5356073379516602
training_loss: 0.5641174912452698
validation_loss: 0.47347837686538696
validation_accuracy: 0.828125
validation_loss: 0.49446824193000793
validation_accuracy: 0.82421875
validation_loss: 0.6000106334686279
validation_accuracy: 0.81640625
validation_loss: 0.538061261177063
validation_accuracy: 0.79296875
validation_loss: 0.5612260103225708
validation_accuracy: 0.81640625
validation_loss: 0.47388774156570435
validation_accuracy: 0.81640625
validation_loss: 0.4438047409057617
validation_accuracy: 0.8515625
validation_loss: 0.5475067496299744
validation_accuracy: 0.8203125
validation_loss: 0.4304671883583069
validation_accuracy: 0.859375
validation_loss: 0.527254581451416
validation_accuracy: 0.80078125
validation_loss: 0.5520495176315308
validation_accuracy: 0.80078125
validation_loss: 0.6442062258720398
validation_accuracy: 0.765625
validation_loss: 0.6707653403282166
validation_accuracy: 0.76953125
validation_loss: 0.5902284979820251
validation_accuracy: 0.82421875
validation_loss: 0.5468993782997131
validation_accuracy: 0.8203125
validation_loss: 0.5835436582565308
validation_accuracy: 0.796875
validation_loss: 0.5141422152519226
validation_accuracy: 0.80859375
validation_loss: 0.38793089985847473
validation_accuracy: 0.87109375
validation_loss: 0.550535261631012
validation_accuracy: 0.8046875
validation_loss: 0.619522213935852
validation_accuracy: 0.8046875
validation_loss: 0.6240836977958679
validation_accuracy: 0.7890625
validation_loss: 0.6378815174102783
validation_accuracy: 0.80078125
validation_loss: 0.5261193513870239
validation_accuracy: 0.79296875
validation_loss: 0.47838538885116577
validation_accuracy: 0.828125
validation_loss: 0.4837169051170349
validation_accuracy: 0.8125
validation_loss: 0.6015886664390564
validation_accuracy: 0.80078125
validation_loss: 0.6033933162689209
validation_accuracy: 0.796875
validation_loss: 0.47390615940093994
validation_accuracy: 0.80859375
validation_loss: 0.5093345046043396
validation_accuracy: 0.82421875
validation_loss: 0.48617446422576904
validation_accuracy: 0.8359375
validation_loss: 0.525968611240387
validation_accuracy: 0.8203125
validation_loss: 0.581759512424469
validation_accuracy: 0.77734375
validation_loss: 0.4932798445224762
validation_accuracy: 0.79296875
validation_loss: 0.5274633765220642
validation_accuracy: 0.82421875
validation_loss: 0.6041293144226074
validation_accuracy: 0.78125
validation_loss: 0.5234768986701965
validation_accuracy: 0.8125
validation_loss: 0.47886449098587036
validation_accuracy: 0.83203125
validation_loss: 0.5706772804260254
validation_accuracy: 0.8046875
validation_loss: 0.4868151545524597
validation_accuracy: 0.83203125
validation_loss: 0.33785322308540344
validation_accuracy: 0.875
epoch 4/15
training_loss: 0.4886983335018158
training_loss: 0.45920586585998535
training_loss: 0.5309303402900696
training_loss: 0.6316802501678467
training_loss: 0.5670273900032043
training_loss: 0.4790692925453186
training_loss: 0.48665285110473633
training_loss: 0.4052374064922333
training_loss: 0.42904162406921387
training_loss: 0.48726725578308105
training_loss: 0.482866108417511
training_loss: 0.4905463457107544
training_loss: 0.43935686349868774
training_loss: 0.5193017721176147
training_loss: 0.5138756036758423
training_loss: 0.5046340227127075
training_loss: 0.502894937992096
training_loss: 0.5190036296844482
training_loss: 0.49054890871047974
training_loss: 0.48152801394462585
training_loss: 0.4660114347934723
training_loss: 0.48375365138053894
training_loss: 0.5072506666183472
training_loss: 0.44514408707618713
training_loss: 0.39660927653312683
training_loss: 0.467715322971344
training_loss: 0.4551869332790375
training_loss: 0.5023422837257385
training_loss: 0.46132540702819824
training_loss: 0.47554197907447815
training_loss: 0.5539568662643433
training_loss: 0.4302590787410736
training_loss: 0.4495541453361511
training_loss: 0.44164466857910156
training_loss: 0.45187851786613464
training_loss: 0.4720931351184845
training_loss: 0.6233386993408203
training_loss: 0.44636720418930054
training_loss: 0.6072090864181519
training_loss: 0.5036351680755615
training_loss: 0.4866047203540802
training_loss: 0.45822712779045105
training_loss: 0.48056724667549133
training_loss: 0.5559083223342896
training_loss: 0.4619849920272827
training_loss: 0.4210231900215149
training_loss: 0.4962438941001892
training_loss: 0.454246461391449
training_loss: 0.4544799029827118
training_loss: 0.5493128299713135
training_loss: 0.4464823305606842
training_loss: 0.5352093577384949
training_loss: 0.5042681097984314
training_loss: 0.4273596704006195
training_loss: 0.506416916847229
training_loss: 0.500354528427124
training_loss: 0.5333911776542664
training_loss: 0.45211416482925415
training_loss: 0.434530645608902
training_loss: 0.43951189517974854
training_loss: 0.5465191602706909
training_loss: 0.4418518543243408
training_loss: 0.5162569284439087
training_loss: 0.49296969175338745
training_loss: 0.46531927585601807
training_loss: 0.4285126328468323
training_loss: 0.5906333923339844
training_loss: 0.4745250940322876
training_loss: 0.4560765027999878
training_loss: 0.49883395433425903
training_loss: 0.5891761779785156
training_loss: 0.4664252996444702
training_loss: 0.48854726552963257
training_loss: 0.42808258533477783
training_loss: 0.4814402759075165
training_loss: 0.5520728826522827
training_loss: 0.5066956877708435
training_loss: 0.4614129662513733
training_loss: 0.4663650095462799
training_loss: 0.4672496020793915
training_loss: 0.5240806937217712
training_loss: 0.5017848014831543
training_loss: 0.4718689024448395
training_loss: 0.4674004316329956
training_loss: 0.4189353287220001
training_loss: 0.6110782027244568
training_loss: 0.439452588558197
training_loss: 0.5069640278816223
training_loss: 0.5748335123062134
training_loss: 0.4608827233314514
training_loss: 0.41762787103652954
training_loss: 0.5411193370819092
training_loss: 0.4651886522769928
training_loss: 0.4987049698829651
training_loss: 0.4923214316368103
training_loss: 0.4907461106777191
training_loss: 0.40890586376190186
training_loss: 0.46844372153282166
training_loss: 0.4705166816711426
training_loss: 0.5003859996795654
training_loss: 0.5769189596176147
training_loss: 0.45480549335479736
training_loss: 0.5040355920791626
training_loss: 0.5268290042877197
training_loss: 0.46956562995910645
training_loss: 0.4282166361808777
training_loss: 0.3779348134994507
training_loss: 0.5166958570480347
training_loss: 0.5236625671386719
training_loss: 0.44322437047958374
training_loss: 0.4450755715370178
training_loss: 0.4926459789276123
training_loss: 0.4097106456756592
training_loss: 0.5639458894729614
training_loss: 0.45281848311424255
training_loss: 0.5220546126365662
training_loss: 0.44743889570236206
training_loss: 0.52311772108078
training_loss: 0.48097923398017883
training_loss: 0.5402818918228149
training_loss: 0.5240747332572937
training_loss: 0.48805153369903564
training_loss: 0.5550518035888672
training_loss: 0.4837855100631714
training_loss: 0.5204288959503174
training_loss: 0.4512259066104889
training_loss: 0.4234187602996826
training_loss: 0.5160669684410095
training_loss: 0.5334267020225525
training_loss: 0.52005934715271
training_loss: 0.5895126461982727
training_loss: 0.4203217625617981
training_loss: 0.43344610929489136
training_loss: 0.4408460557460785
training_loss: 0.5428434610366821
training_loss: 0.4531428813934326
training_loss: 0.5794841647148132
training_loss: 0.5512102246284485
training_loss: 0.527440071105957
training_loss: 0.46230629086494446
training_loss: 0.45220568776130676
training_loss: 0.4300101399421692
training_loss: 0.43539097905158997
training_loss: 0.47536179423332214
training_loss: 0.4582626521587372
training_loss: 0.4193776547908783
training_loss: 0.4600498080253601
training_loss: 0.4850204885005951
training_loss: 0.4505655765533447
training_loss: 0.5592290163040161
training_loss: 0.5168949961662292
training_loss: 0.5397676229476929
training_loss: 0.5160131454467773
training_loss: 0.4590694308280945
training_loss: 0.39262375235557556
training_loss: 0.4492705464363098
training_loss: 0.6078237891197205
training_loss: 0.5214492082595825
training_loss: 0.5284940004348755
training_loss: 0.5031017661094666
training_loss: 0.5289127826690674
training_loss: 0.5258134603500366
training_loss: 0.4109281003475189
training_loss: 0.42372608184814453
training_loss: 0.48902183771133423
training_loss: 0.4640394151210785
training_loss: 0.41670992970466614
training_loss: 0.491626501083374
training_loss: 0.481656938791275
training_loss: 0.3472394645214081
training_loss: 0.4773121178150177
training_loss: 0.4740633964538574
training_loss: 0.45335808396339417
training_loss: 0.495039165019989
training_loss: 0.5026214122772217
training_loss: 0.42852866649627686
training_loss: 0.6021794676780701
training_loss: 0.4532029628753662
training_loss: 0.37521788477897644
training_loss: 0.45053648948669434
training_loss: 0.4777519404888153
training_loss: 0.4729800522327423
training_loss: 0.5722712874412537
training_loss: 0.4374762177467346
training_loss: 0.4654707908630371
training_loss: 0.43770721554756165
training_loss: 0.45367002487182617
training_loss: 0.4026259779930115
training_loss: 0.45963242650032043
training_loss: 0.5155832767486572
training_loss: 0.42076361179351807
training_loss: 0.48967885971069336
training_loss: 0.562175989151001
training_loss: 0.4708087742328644
training_loss: 0.5176908373832703
training_loss: 0.4774283170700073
training_loss: 0.40883347392082214
training_loss: 0.49107804894447327
training_loss: 0.5066563487052917
training_loss: 0.5624992847442627
training_loss: 0.4260379672050476
training_loss: 0.47856324911117554
training_loss: 0.43293964862823486
training_loss: 0.3789801001548767
training_loss: 0.4255746603012085
training_loss: 0.48319801688194275
training_loss: 0.5252455472946167
training_loss: 0.49171319603919983
training_loss: 0.5077028274536133
training_loss: 0.44704219698905945
training_loss: 0.431641161441803
training_loss: 0.5348614454269409
training_loss: 0.48982739448547363
training_loss: 0.5940737724304199
training_loss: 0.5026931166648865
training_loss: 0.4815371334552765
training_loss: 0.5226366519927979
training_loss: 0.4559442400932312
training_loss: 0.4853278398513794
training_loss: 0.45750027894973755
training_loss: 0.4487581253051758
training_loss: 0.5077293515205383
training_loss: 0.506734311580658
training_loss: 0.4901547431945801
training_loss: 0.4427449703216553
training_loss: 0.43546587228775024
training_loss: 0.6466934680938721
training_loss: 0.5275346040725708
training_loss: 0.561072826385498
training_loss: 0.506260335445404
training_loss: 0.5481715202331543
training_loss: 0.4315793812274933
training_loss: 0.4506474733352661
training_loss: 0.5797966718673706
training_loss: 0.45889854431152344
validation_loss: 0.4455372095108032
validation_accuracy: 0.84375
validation_loss: 0.44704675674438477
validation_accuracy: 0.85546875
validation_loss: 0.5952265858650208
validation_accuracy: 0.8046875
validation_loss: 0.4682322144508362
validation_accuracy: 0.84375
validation_loss: 0.5226395726203918
validation_accuracy: 0.83203125
validation_loss: 0.4563446342945099
validation_accuracy: 0.828125
validation_loss: 0.4680536687374115
validation_accuracy: 0.83984375
validation_loss: 0.5163981914520264
validation_accuracy: 0.84765625
validation_loss: 0.4122306704521179
validation_accuracy: 0.84765625
validation_loss: 0.506855845451355
validation_accuracy: 0.82421875
validation_loss: 0.48783648014068604
validation_accuracy: 0.83984375
validation_loss: 0.6735907196998596
validation_accuracy: 0.77734375
validation_loss: 0.6277198791503906
validation_accuracy: 0.796875
validation_loss: 0.5762317180633545
validation_accuracy: 0.7890625
validation_loss: 0.5242624878883362
validation_accuracy: 0.828125
validation_loss: 0.5672551989555359
validation_accuracy: 0.80859375
validation_loss: 0.517449140548706
validation_accuracy: 0.83203125
validation_loss: 0.34370002150535583
validation_accuracy: 0.88671875
validation_loss: 0.5698339343070984
validation_accuracy: 0.80078125
validation_loss: 0.5928037166595459
validation_accuracy: 0.8046875
validation_loss: 0.5569474101066589
validation_accuracy: 0.83203125
validation_loss: 0.6422440409660339
validation_accuracy: 0.78515625
validation_loss: 0.5390933156013489
validation_accuracy: 0.81640625
validation_loss: 0.48992177844047546
validation_accuracy: 0.80859375
validation_loss: 0.483903706073761
validation_accuracy: 0.81640625
validation_loss: 0.5988062024116516
validation_accuracy: 0.76953125
validation_loss: 0.5472694635391235
validation_accuracy: 0.8046875
validation_loss: 0.5081421732902527
validation_accuracy: 0.7734375
validation_loss: 0.5141687989234924
validation_accuracy: 0.84765625
validation_loss: 0.4558669626712799
validation_accuracy: 0.83984375
validation_loss: 0.5116892457008362
validation_accuracy: 0.82421875
validation_loss: 0.5590834021568298
validation_accuracy: 0.79296875
validation_loss: 0.472965270280838
validation_accuracy: 0.83984375
validation_loss: 0.4694174528121948
validation_accuracy: 0.828125
validation_loss: 0.5995867848396301
validation_accuracy: 0.78515625
validation_loss: 0.5324385166168213
validation_accuracy: 0.828125
validation_loss: 0.4770132899284363
validation_accuracy: 0.8125
validation_loss: 0.5659893155097961
validation_accuracy: 0.828125
validation_loss: 0.45287102460861206
validation_accuracy: 0.86328125
validation_loss: 0.3191993236541748
validation_accuracy: 0.875
epoch 5/15
training_loss: 0.4668683409690857
training_loss: 0.4254165291786194
training_loss: 0.44415464997291565
training_loss: 0.48179155588150024
training_loss: 0.4131122827529907
training_loss: 0.43078485131263733
training_loss: 0.47052544355392456
training_loss: 0.44348326325416565
training_loss: 0.42187824845314026
training_loss: 0.5936338901519775
training_loss: 0.49503976106643677
training_loss: 0.4933660626411438
training_loss: 0.3951207101345062
training_loss: 0.44605088233947754
training_loss: 0.502170979976654
training_loss: 0.47039794921875
training_loss: 0.44218137860298157
training_loss: 0.47702324390411377
training_loss: 0.4559183716773987
training_loss: 0.5661718845367432
training_loss: 0.43792492151260376
training_loss: 0.45047569274902344
training_loss: 0.5514415502548218
training_loss: 0.45495474338531494
training_loss: 0.5584551692008972
training_loss: 0.476237952709198
training_loss: 0.533643364906311
training_loss: 0.5282706618309021
training_loss: 0.4634290635585785
training_loss: 0.4081772267818451
training_loss: 0.4321540594100952
training_loss: 0.3843894302845001
training_loss: 0.5852004289627075
training_loss: 0.500034749507904
training_loss: 0.4410100281238556
training_loss: 0.4643861651420593
training_loss: 0.5180895924568176
training_loss: 0.47686871886253357
training_loss: 0.43131130933761597
training_loss: 0.5127626657485962
training_loss: 0.44088372588157654
training_loss: 0.48953354358673096
training_loss: 0.41430309414863586
training_loss: 0.5034040808677673
training_loss: 0.47259747982025146
training_loss: 0.5098199844360352
training_loss: 0.5990691781044006
training_loss: 0.4078795313835144
training_loss: 0.5160480737686157
training_loss: 0.4069419801235199
training_loss: 0.47743654251098633
training_loss: 0.47458550333976746
training_loss: 0.5103728771209717
training_loss: 0.5184505581855774
training_loss: 0.4741557836532593
training_loss: 0.4514232873916626
training_loss: 0.40058913826942444
training_loss: 0.4428468346595764
training_loss: 0.47572287917137146
training_loss: 0.4313446283340454
training_loss: 0.4780155122280121
training_loss: 0.4672433137893677
training_loss: 0.4251554608345032
training_loss: 0.6131296157836914
training_loss: 0.3970204293727875
training_loss: 0.4909748435020447
training_loss: 0.4635656774044037
training_loss: 0.45554468035697937
training_loss: 0.457427442073822
training_loss: 0.44917190074920654
training_loss: 0.5771588683128357
training_loss: 0.5655314922332764
training_loss: 0.5367221832275391
training_loss: 0.4121021032333374
training_loss: 0.5069203972816467
training_loss: 0.5040746927261353
training_loss: 0.5076671838760376
training_loss: 0.46639883518218994
training_loss: 0.41212892532348633
training_loss: 0.44269904494285583
training_loss: 0.46665555238723755
training_loss: 0.46487098932266235
training_loss: 0.501107931137085
training_loss: 0.39552271366119385
training_loss: 0.41543763875961304
training_loss: 0.4791758954524994
training_loss: 0.5335886478424072
training_loss: 0.5523443818092346
training_loss: 0.4315967261791229
training_loss: 0.48600196838378906
training_loss: 0.41642922163009644
training_loss: 0.5309839248657227
training_loss: 0.4673304855823517
training_loss: 0.4158802330493927
training_loss: 0.4282139539718628
training_loss: 0.5373587012290955
training_loss: 0.4985204339027405
training_loss: 0.42771419882774353
training_loss: 0.43511658906936646
training_loss: 0.5205767154693604
training_loss: 0.4123344421386719
training_loss: 0.4611683487892151
training_loss: 0.5244282484054565
training_loss: 0.4584658145904541
training_loss: 0.4810701310634613
training_loss: 0.4849547743797302
training_loss: 0.5153937935829163
training_loss: 0.4300254285335541
training_loss: 0.4828309714794159
training_loss: 0.4961349368095398
training_loss: 0.41057538986206055
training_loss: 0.47871509194374084
training_loss: 0.5708343386650085
training_loss: 0.5347228646278381
training_loss: 0.4459627568721771
training_loss: 0.5399666428565979
training_loss: 0.5217373371124268
training_loss: 0.4870504140853882
training_loss: 0.467468798160553
training_loss: 0.4184039831161499
training_loss: 0.3771650195121765
training_loss: 0.4328295886516571
training_loss: 0.43378111720085144
training_loss: 0.41029420495033264
training_loss: 0.41597574949264526
training_loss: 0.4538751244544983
training_loss: 0.4007209539413452
training_loss: 0.3998807668685913
training_loss: 0.43540453910827637
training_loss: 0.4977591335773468
training_loss: 0.5206832885742188
training_loss: 0.393760621547699
training_loss: 0.5653458833694458
training_loss: 0.5083109140396118
training_loss: 0.4894906282424927
training_loss: 0.4904268682003021
training_loss: 0.5046697854995728
training_loss: 0.46161919832229614
training_loss: 0.4742653965950012
training_loss: 0.5453422665596008
training_loss: 0.41191259026527405
training_loss: 0.4968107044696808
training_loss: 0.47658225893974304
training_loss: 0.46237510442733765
training_loss: 0.4723391532897949
training_loss: 0.46678078174591064
training_loss: 0.3729432225227356
training_loss: 0.4839627742767334
training_loss: 0.5796054601669312
training_loss: 0.4712255895137787
training_loss: 0.4521647095680237
training_loss: 0.49112215638160706
training_loss: 0.38558584451675415
training_loss: 0.419513463973999
training_loss: 0.439807265996933
training_loss: 0.4206690192222595
training_loss: 0.4530951976776123
training_loss: 0.4831552505493164
training_loss: 0.5421611070632935
training_loss: 0.37321656942367554
training_loss: 0.5115940570831299
training_loss: 0.5178184509277344
training_loss: 0.4923558235168457
training_loss: 0.4695037603378296
training_loss: 0.42149946093559265
training_loss: 0.4335560202598572
training_loss: 0.5367496609687805
training_loss: 0.4454768896102905
training_loss: 0.5371972918510437
training_loss: 0.4948302209377289
training_loss: 0.5185980200767517
training_loss: 0.4114227890968323
training_loss: 0.43164315819740295
training_loss: 0.45418840646743774
training_loss: 0.46370211243629456
training_loss: 0.40323546528816223
training_loss: 0.5029700398445129
training_loss: 0.5985400080680847
training_loss: 0.49675288796424866
training_loss: 0.4496559500694275
training_loss: 0.5517855286598206
training_loss: 0.44826367497444153
training_loss: 0.5112674832344055
training_loss: 0.5146986246109009
training_loss: 0.43965303897857666
training_loss: 0.43892303109169006
training_loss: 0.44161251187324524
training_loss: 0.5376126170158386
training_loss: 0.4321569800376892
training_loss: 0.4074113667011261
training_loss: 0.509733259677887
training_loss: 0.48862290382385254
training_loss: 0.3842487931251526
training_loss: 0.4368389844894409
training_loss: 0.4573341906070709
training_loss: 0.4725862741470337
training_loss: 0.36268121004104614
training_loss: 0.5662798285484314
training_loss: 0.41137129068374634
training_loss: 0.3808709979057312
training_loss: 0.49863120913505554
training_loss: 0.40733128786087036
training_loss: 0.4548720717430115
training_loss: 0.4845848083496094
training_loss: 0.40555045008659363
training_loss: 0.5551354289054871
training_loss: 0.5140523910522461
training_loss: 0.4734426736831665
training_loss: 0.7047502994537354
training_loss: 0.5330174565315247
training_loss: 0.46095627546310425
training_loss: 0.588954746723175
training_loss: 0.5061973929405212
training_loss: 0.47484272718429565
training_loss: 0.44956889748573303
training_loss: 0.4138672947883606
training_loss: 0.5339751839637756
training_loss: 0.3890921175479889
training_loss: 0.3938273787498474
training_loss: 0.46122676134109497
training_loss: 0.5997105240821838
training_loss: 0.5387513041496277
training_loss: 0.4547117054462433
training_loss: 0.567784309387207
training_loss: 0.5240830183029175
training_loss: 0.5159671902656555
training_loss: 0.4092090129852295
training_loss: 0.41314756870269775
training_loss: 0.4651438891887665
training_loss: 0.47980183362960815
training_loss: 0.35728469491004944
training_loss: 0.4404078423976898
training_loss: 0.4625757336616516
training_loss: 0.4271121323108673
training_loss: 0.602973997592926
validation_loss: 0.4452357292175293
validation_accuracy: 0.84375
validation_loss: 0.44011059403419495
validation_accuracy: 0.85546875
validation_loss: 0.5885870456695557
validation_accuracy: 0.81640625
validation_loss: 0.4574398100376129
validation_accuracy: 0.84375
validation_loss: 0.5089318156242371
validation_accuracy: 0.83984375
validation_loss: 0.45200812816619873
validation_accuracy: 0.828125
validation_loss: 0.4669424295425415
validation_accuracy: 0.84765625
validation_loss: 0.5138261318206787
validation_accuracy: 0.84375
validation_loss: 0.40347591042518616
validation_accuracy: 0.83984375
validation_loss: 0.4937865734100342
validation_accuracy: 0.8359375
validation_loss: 0.47863078117370605
validation_accuracy: 0.8203125
validation_loss: 0.6543366312980652
validation_accuracy: 0.77734375
validation_loss: 0.6217586994171143
validation_accuracy: 0.80078125
validation_loss: 0.5631813406944275
validation_accuracy: 0.78515625
validation_loss: 0.5073175430297852
validation_accuracy: 0.8359375
validation_loss: 0.5461064577102661
validation_accuracy: 0.83203125
validation_loss: 0.518269419670105
validation_accuracy: 0.83203125
validation_loss: 0.3406990170478821
validation_accuracy: 0.88671875
validation_loss: 0.580940306186676
validation_accuracy: 0.79296875
validation_loss: 0.5817674398422241
validation_accuracy: 0.8125
validation_loss: 0.5414391160011292
validation_accuracy: 0.8359375
validation_loss: 0.6245311498641968
validation_accuracy: 0.796875
validation_loss: 0.5423125624656677
validation_accuracy: 0.82421875
validation_loss: 0.4749564528465271
validation_accuracy: 0.8203125
validation_loss: 0.4692673981189728
validation_accuracy: 0.8125
validation_loss: 0.5826354622840881
validation_accuracy: 0.78125
validation_loss: 0.5322897434234619
validation_accuracy: 0.80859375
validation_loss: 0.4960419535636902
validation_accuracy: 0.796875
validation_loss: 0.5091469883918762
validation_accuracy: 0.83984375
validation_loss: 0.44707274436950684
validation_accuracy: 0.8515625
validation_loss: 0.5025971531867981
validation_accuracy: 0.82421875
validation_loss: 0.5504135489463806
validation_accuracy: 0.7890625
validation_loss: 0.44685760140419006
validation_accuracy: 0.83984375
validation_loss: 0.47366511821746826
validation_accuracy: 0.828125
validation_loss: 0.5880031585693359
validation_accuracy: 0.78515625
validation_loss: 0.5145415663719177
validation_accuracy: 0.84765625
validation_loss: 0.46720588207244873
validation_accuracy: 0.8203125
validation_loss: 0.5551007986068726
validation_accuracy: 0.8203125
validation_loss: 0.44005778431892395
validation_accuracy: 0.86328125
validation_loss: 0.32738780975341797
validation_accuracy: 0.875
epoch 6/15
training_loss: 0.5545579195022583
training_loss: 0.45333874225616455
training_loss: 0.3984154760837555
training_loss: 0.424793004989624
training_loss: 0.41937944293022156
training_loss: 0.6208471059799194
training_loss: 0.38991978764533997
training_loss: 0.43387725949287415
training_loss: 0.4898151755332947
training_loss: 0.5552729964256287
training_loss: 0.5511184930801392
training_loss: 0.477222740650177
training_loss: 0.45668894052505493
training_loss: 0.3918167054653168
training_loss: 0.484732061624527
training_loss: 0.45291903614997864
training_loss: 0.5375767350196838
training_loss: 0.40952184796333313
training_loss: 0.4445095956325531
training_loss: 0.5570880174636841
training_loss: 0.4499686360359192
training_loss: 0.4521961510181427
training_loss: 0.4974867105484009
training_loss: 0.47528040409088135
training_loss: 0.44044792652130127
training_loss: 0.4089829623699188
training_loss: 0.44015178084373474
training_loss: 0.4535187780857086
training_loss: 0.5441926121711731
training_loss: 0.5062011480331421
training_loss: 0.5103521943092346
training_loss: 0.4626559913158417
training_loss: 0.451560378074646
training_loss: 0.44708260893821716
training_loss: 0.4256305694580078
training_loss: 0.4573134779930115
training_loss: 0.45117661356925964
training_loss: 0.40821921825408936
training_loss: 0.46906325221061707
training_loss: 0.4314710199832916
training_loss: 0.46431928873062134
training_loss: 0.46191921830177307
training_loss: 0.5193176865577698
training_loss: 0.4315164387226105
training_loss: 0.40155458450317383
training_loss: 0.4602159857749939
training_loss: 0.49044570326805115
training_loss: 0.4724064767360687
training_loss: 0.3658772110939026
training_loss: 0.501616358757019
training_loss: 0.5366655588150024
training_loss: 0.49788472056388855
training_loss: 0.4645175635814667
training_loss: 0.4853144884109497
training_loss: 0.4868512451648712
training_loss: 0.3973855674266815
training_loss: 0.4685780704021454
training_loss: 0.4016039967536926
training_loss: 0.40845412015914917
training_loss: 0.44692593812942505
training_loss: 0.37971967458724976
training_loss: 0.5393998622894287
training_loss: 0.4266589879989624
training_loss: 0.4621056318283081
training_loss: 0.385002076625824
training_loss: 0.49843984842300415
training_loss: 0.5251595377922058
training_loss: 0.4801420569419861
training_loss: 0.42991209030151367
training_loss: 0.4913346469402313
training_loss: 0.46910619735717773
training_loss: 0.580672025680542
training_loss: 0.3770522177219391
training_loss: 0.4244418144226074
training_loss: 0.4683430790901184
training_loss: 0.5203495025634766
training_loss: 0.4500604569911957
training_loss: 0.38917696475982666
training_loss: 0.44439688324928284
training_loss: 0.5252302885055542
training_loss: 0.42862650752067566
training_loss: 0.5137557983398438
training_loss: 0.5295616984367371
training_loss: 0.3884406089782715
training_loss: 0.4398415684700012
training_loss: 0.36938074231147766
training_loss: 0.4358411431312561
training_loss: 0.45678871870040894
training_loss: 0.44798654317855835
training_loss: 0.5244774222373962
training_loss: 0.44949835538864136
training_loss: 0.472367525100708
training_loss: 0.42074882984161377
training_loss: 0.42469334602355957
training_loss: 0.4894621670246124
training_loss: 0.3932461738586426
training_loss: 0.4188689589500427
training_loss: 0.3678959906101227
training_loss: 0.43886828422546387
training_loss: 0.489402711391449
training_loss: 0.5054304599761963
training_loss: 0.4769026041030884
training_loss: 0.5316920876502991
training_loss: 0.4770953059196472
training_loss: 0.45992767810821533
training_loss: 0.38059717416763306
training_loss: 0.4647422134876251
training_loss: 0.4015120565891266
training_loss: 0.5015698075294495
training_loss: 0.5338134169578552
training_loss: 0.4370020627975464
training_loss: 0.47317707538604736
training_loss: 0.5860800743103027
training_loss: 0.43696174025535583
training_loss: 0.44148504734039307
training_loss: 0.4298644959926605
training_loss: 0.4152599275112152
training_loss: 0.3977920711040497
training_loss: 0.4777248799800873
training_loss: 0.4888537526130676
training_loss: 0.48639732599258423
training_loss: 0.4874323308467865
training_loss: 0.532315731048584
training_loss: 0.421619713306427
training_loss: 0.45665502548217773
training_loss: 0.41136816143989563
training_loss: 0.3861374855041504
training_loss: 0.47424453496932983
training_loss: 0.5414719581604004
training_loss: 0.40124109387397766
training_loss: 0.42109814286231995
training_loss: 0.501336395740509
training_loss: 0.4990157186985016
training_loss: 0.45075201988220215
training_loss: 0.3966103792190552
training_loss: 0.4981657564640045
training_loss: 0.44781652092933655
training_loss: 0.3831331729888916
training_loss: 0.5307350158691406
training_loss: 0.4932456314563751
training_loss: 0.540473461151123
training_loss: 0.4932302236557007
training_loss: 0.4983457028865814
training_loss: 0.431516170501709
training_loss: 0.4714426100254059
training_loss: 0.43402278423309326
training_loss: 0.496864914894104
training_loss: 0.4184667468070984
training_loss: 0.5425846576690674
training_loss: 0.48747172951698303
training_loss: 0.531611442565918
training_loss: 0.4782986640930176
training_loss: 0.452254056930542
training_loss: 0.4342494010925293
training_loss: 0.5231201648712158
training_loss: 0.4847332835197449
training_loss: 0.5661891102790833
training_loss: 0.4492393434047699
training_loss: 0.4406687021255493
training_loss: 0.48237842321395874
training_loss: 0.5550755262374878
training_loss: 0.5485521554946899
training_loss: 0.5500513315200806
training_loss: 0.3878154456615448
training_loss: 0.4112006425857544
training_loss: 0.46750298142433167
training_loss: 0.465004563331604
training_loss: 0.4895433485507965
training_loss: 0.357984721660614
training_loss: 0.5440822839736938
training_loss: 0.45578011870384216
training_loss: 0.48230016231536865
training_loss: 0.49837344884872437
training_loss: 0.5111048221588135
training_loss: 0.4777736961841583
training_loss: 0.4363710880279541
training_loss: 0.4209689497947693
training_loss: 0.41196712851524353
training_loss: 0.4318988621234894
training_loss: 0.4940119981765747
training_loss: 0.4423586428165436
training_loss: 0.43596509099006653
training_loss: 0.42699626088142395
training_loss: 0.4277232885360718
training_loss: 0.44358474016189575
training_loss: 0.4882643222808838
training_loss: 0.4697318375110626
training_loss: 0.41174018383026123
training_loss: 0.5494735836982727
training_loss: 0.4884655177593231
training_loss: 0.5283669233322144
training_loss: 0.5079028010368347
training_loss: 0.5028836131095886
training_loss: 0.5334977507591248
training_loss: 0.5936278104782104
training_loss: 0.6241641044616699
training_loss: 0.4683681130409241
training_loss: 0.44288212060928345
training_loss: 0.5458557605743408
training_loss: 0.5224644541740417
training_loss: 0.45163893699645996
training_loss: 0.5402204394340515
training_loss: 0.41934117674827576
training_loss: 0.483692467212677
training_loss: 0.48020514845848083
training_loss: 0.49661093950271606
training_loss: 0.5244405269622803
training_loss: 0.4893608093261719
training_loss: 0.4911291301250458
training_loss: 0.33589816093444824
training_loss: 0.47746962308883667
training_loss: 0.5040251612663269
training_loss: 0.5072116255760193
training_loss: 0.42435958981513977
training_loss: 0.4386909306049347
training_loss: 0.4445250928401947
training_loss: 0.44342485070228577
training_loss: 0.42473775148391724
training_loss: 0.45289403200149536
training_loss: 0.4848555326461792
training_loss: 0.4413025379180908
training_loss: 0.48013919591903687
training_loss: 0.40496182441711426
training_loss: 0.3856523334980011
training_loss: 0.47507429122924805
training_loss: 0.4004118740558624
training_loss: 0.4393041729927063
training_loss: 0.4750443398952484
training_loss: 0.4981064200401306
training_loss: 0.46129029989242554
training_loss: 0.48967042565345764
training_loss: 0.3776422142982483
training_loss: 0.4109101891517639
training_loss: 0.48402467370033264
training_loss: 0.3762398958206177
validation_loss: 0.4242124855518341
validation_accuracy: 0.85546875
validation_loss: 0.43162044882774353
validation_accuracy: 0.8515625
validation_loss: 0.5858156085014343
validation_accuracy: 0.80859375
validation_loss: 0.47811359167099
validation_accuracy: 0.83203125
validation_loss: 0.5164746046066284
validation_accuracy: 0.8359375
validation_loss: 0.4348353147506714
validation_accuracy: 0.8359375
validation_loss: 0.43065592646598816
validation_accuracy: 0.859375
validation_loss: 0.5044295787811279
validation_accuracy: 0.84765625
validation_loss: 0.3883012533187866
validation_accuracy: 0.859375
validation_loss: 0.5140954256057739
validation_accuracy: 0.81640625
validation_loss: 0.4947241544723511
validation_accuracy: 0.828125
validation_loss: 0.6453530192375183
validation_accuracy: 0.7734375
validation_loss: 0.60771644115448
validation_accuracy: 0.796875
validation_loss: 0.5472193360328674
validation_accuracy: 0.80859375
validation_loss: 0.511318027973175
validation_accuracy: 0.82421875
validation_loss: 0.5372644662857056
validation_accuracy: 0.83203125
validation_loss: 0.4904783368110657
validation_accuracy: 0.828125
validation_loss: 0.3474404513835907
validation_accuracy: 0.87109375
validation_loss: 0.5278266668319702
validation_accuracy: 0.80859375
validation_loss: 0.5781707763671875
validation_accuracy: 0.80859375
validation_loss: 0.5601946711540222
validation_accuracy: 0.828125
validation_loss: 0.6307759881019592
validation_accuracy: 0.79296875
validation_loss: 0.5033041834831238
validation_accuracy: 0.8203125
validation_loss: 0.4595028758049011
validation_accuracy: 0.83984375
validation_loss: 0.4656982123851776
validation_accuracy: 0.8203125
validation_loss: 0.5900240540504456
validation_accuracy: 0.78515625
validation_loss: 0.5370151400566101
validation_accuracy: 0.82421875
validation_loss: 0.46716731786727905
validation_accuracy: 0.8046875
validation_loss: 0.49083447456359863
validation_accuracy: 0.84765625
validation_loss: 0.437618225812912
validation_accuracy: 0.84375
validation_loss: 0.4917331039905548
validation_accuracy: 0.80859375
validation_loss: 0.536984920501709
validation_accuracy: 0.8046875
validation_loss: 0.46183955669403076
validation_accuracy: 0.8515625
validation_loss: 0.4770681858062744
validation_accuracy: 0.83203125
validation_loss: 0.574918806552887
validation_accuracy: 0.79296875
validation_loss: 0.5101025104522705
validation_accuracy: 0.8203125
validation_loss: 0.4476916790008545
validation_accuracy: 0.82421875
validation_loss: 0.5419150590896606
validation_accuracy: 0.8125
validation_loss: 0.4349352717399597
validation_accuracy: 0.859375
validation_loss: 0.33725452423095703
validation_accuracy: 0.8125
epoch 7/15
training_loss: 0.5335568785667419
training_loss: 0.4216189384460449
training_loss: 0.41049909591674805
training_loss: 0.4922924339771271
training_loss: 0.44940847158432007
training_loss: 0.5122100710868835
training_loss: 0.43942320346832275
training_loss: 0.5414932370185852
training_loss: 0.4210977554321289
training_loss: 0.5032920837402344
training_loss: 0.5037283897399902
training_loss: 0.44774454832077026
training_loss: 0.48095938563346863
training_loss: 0.39561060070991516
training_loss: 0.41598522663116455
training_loss: 0.5455117225646973
training_loss: 0.46204042434692383
training_loss: 0.4223851263523102
training_loss: 0.5495676398277283
training_loss: 0.4960136413574219
training_loss: 0.505893349647522
training_loss: 0.46533095836639404
training_loss: 0.46086764335632324
training_loss: 0.5181437730789185
training_loss: 0.5124786496162415
training_loss: 0.41830840706825256
training_loss: 0.42801499366760254
training_loss: 0.4449838101863861
training_loss: 0.45527124404907227
training_loss: 0.45822495222091675
training_loss: 0.43923962116241455
training_loss: 0.46627989411354065
training_loss: 0.5271854400634766
training_loss: 0.4581674635410309
training_loss: 0.4830118417739868
training_loss: 0.40224015712738037
training_loss: 0.37937891483306885
training_loss: 0.474016398191452
training_loss: 0.5035804510116577
training_loss: 0.5403879880905151
training_loss: 0.3790120780467987
training_loss: 0.4210222065448761
training_loss: 0.47619324922561646
training_loss: 0.5004777908325195
training_loss: 0.5423871278762817
training_loss: 0.4363892078399658
training_loss: 0.483981192111969
training_loss: 0.5664731860160828
training_loss: 0.5916534662246704
training_loss: 0.5120924115180969
training_loss: 0.47990134358406067
training_loss: 0.43508151173591614
training_loss: 0.41679883003234863
training_loss: 0.4735780656337738
training_loss: 0.5195123553276062
training_loss: 0.4514884650707245
training_loss: 0.5335666537284851
training_loss: 0.44308340549468994
training_loss: 0.432613730430603
training_loss: 0.4613376259803772
training_loss: 0.4764638841152191
training_loss: 0.48114535212516785
training_loss: 0.4607303738594055
training_loss: 0.4507550597190857
training_loss: 0.35023409128189087
training_loss: 0.47409969568252563
training_loss: 0.39274486899375916
training_loss: 0.5476046204566956
training_loss: 0.4995073676109314
training_loss: 0.47623395919799805
training_loss: 0.46961456537246704
training_loss: 0.44514769315719604
training_loss: 0.41218268871307373
training_loss: 0.43569061160087585
training_loss: 0.40411752462387085
training_loss: 0.4596245586872101
training_loss: 0.476733922958374
training_loss: 0.3937796652317047
training_loss: 0.47257810831069946
training_loss: 0.6021945476531982
training_loss: 0.37237662076950073
training_loss: 0.3939683437347412
training_loss: 0.4264410138130188
training_loss: 0.47364744544029236
training_loss: 0.3562057912349701
training_loss: 0.4779234826564789
training_loss: 0.4098660945892334
training_loss: 0.5410540103912354
training_loss: 0.4264065623283386
training_loss: 0.43693050742149353
training_loss: 0.5341457724571228
training_loss: 0.4390719532966614
training_loss: 0.5262641310691833
training_loss: 0.5233080983161926
training_loss: 0.4245105981826782
training_loss: 0.401212215423584
training_loss: 0.4167627990245819
training_loss: 0.46415820717811584
training_loss: 0.47430896759033203
training_loss: 0.40462690591812134
training_loss: 0.46376967430114746
training_loss: 0.48899200558662415
training_loss: 0.4514699876308441
training_loss: 0.5138373374938965
training_loss: 0.45315098762512207
training_loss: 0.5314031839370728
training_loss: 0.4008788466453552
training_loss: 0.5174124240875244
training_loss: 0.4222995638847351
training_loss: 0.4608924388885498
training_loss: 0.4714536666870117
training_loss: 0.3714442551136017
training_loss: 0.40647777915000916
training_loss: 0.5012796521186829
training_loss: 0.49560391902923584
training_loss: 0.4780762195587158
training_loss: 0.4251108765602112
training_loss: 0.4567399322986603
training_loss: 0.41220325231552124
training_loss: 0.4499051570892334
training_loss: 0.44891542196273804
training_loss: 0.44435304403305054
training_loss: 0.5164450407028198
training_loss: 0.5061306357383728
training_loss: 0.38905832171440125
training_loss: 0.433620810508728
training_loss: 0.5030794143676758
training_loss: 0.47439202666282654
training_loss: 0.45033618807792664
training_loss: 0.38929933309555054
training_loss: 0.44830751419067383
training_loss: 0.4461173713207245
training_loss: 0.4368939995765686
training_loss: 0.4155729413032532
training_loss: 0.4349372982978821
training_loss: 0.39836421608924866
training_loss: 0.4067612290382385
training_loss: 0.44191351532936096
training_loss: 0.41757428646087646
training_loss: 0.433610200881958
training_loss: 0.437741219997406
training_loss: 0.42995280027389526
training_loss: 0.4920400381088257
training_loss: 0.408791720867157
training_loss: 0.43298691511154175
training_loss: 0.4159057140350342
training_loss: 0.42279231548309326
training_loss: 0.44135019183158875
training_loss: 0.3692321181297302
training_loss: 0.48544129729270935
training_loss: 0.47884896397590637
training_loss: 0.5060088038444519
training_loss: 0.514911413192749
training_loss: 0.5011890530586243
training_loss: 0.5378072261810303
training_loss: 0.43911683559417725
training_loss: 0.5002057552337646
training_loss: 0.5365705490112305
training_loss: 0.387964129447937
training_loss: 0.551291823387146
training_loss: 0.4640918970108032
training_loss: 0.48196864128112793
training_loss: 0.4744265079498291
training_loss: 0.5351123213768005
training_loss: 0.4402836561203003
training_loss: 0.44862839579582214
training_loss: 0.4983516335487366
training_loss: 0.47056281566619873
training_loss: 0.5053432583808899
training_loss: 0.4833170473575592
training_loss: 0.43231841921806335
training_loss: 0.4091953635215759
training_loss: 0.5473664402961731
training_loss: 0.42299172282218933
training_loss: 0.39991363883018494
training_loss: 0.49435555934906006
training_loss: 0.4277473986148834
training_loss: 0.45900923013687134
training_loss: 0.5797843337059021
training_loss: 0.4076016843318939
training_loss: 0.4308946430683136
training_loss: 0.4525468647480011
training_loss: 0.41736096143722534
training_loss: 0.35385069251060486
training_loss: 0.3939490020275116
training_loss: 0.39408403635025024
training_loss: 0.5031479597091675
training_loss: 0.4919213652610779
training_loss: 0.3945568799972534
training_loss: 0.48503342270851135
training_loss: 0.4846190810203552
training_loss: 0.43798699975013733
training_loss: 0.39718204736709595
training_loss: 0.454611599445343
training_loss: 0.40728873014450073
training_loss: 0.5765413641929626
training_loss: 0.4976022243499756
training_loss: 0.47493991255760193
training_loss: 0.402524471282959
training_loss: 0.44838371872901917
training_loss: 0.39778652787208557
training_loss: 0.37550318241119385
training_loss: 0.51079922914505
training_loss: 0.4138175845146179
training_loss: 0.44657501578330994
training_loss: 0.4388711154460907
training_loss: 0.4256002902984619
training_loss: 0.39557313919067383
training_loss: 0.46258145570755005
training_loss: 0.4233153164386749
training_loss: 0.4200458228588104
training_loss: 0.40160831809043884
training_loss: 0.44083520770072937
training_loss: 0.484215646982193
training_loss: 0.46200862526893616
training_loss: 0.4528054893016815
training_loss: 0.4757404327392578
training_loss: 0.466946542263031
training_loss: 0.45075279474258423
training_loss: 0.522489070892334
training_loss: 0.4629703164100647
training_loss: 0.4802439510822296
training_loss: 0.4872725307941437
training_loss: 0.4484575092792511
training_loss: 0.40971824526786804
training_loss: 0.36637991666793823
training_loss: 0.4500262439250946
training_loss: 0.44712886214256287
training_loss: 0.5079702734947205
training_loss: 0.4728749394416809
training_loss: 0.41292840242385864
training_loss: 0.3856407403945923
training_loss: 0.41687339544296265
training_loss: 0.44552043080329895
training_loss: 0.38819968700408936
validation_loss: 0.4155656695365906
validation_accuracy: 0.8515625
validation_loss: 0.43358778953552246
validation_accuracy: 0.85546875
validation_loss: 0.5771012902259827
validation_accuracy: 0.8046875
validation_loss: 0.47666794061660767
validation_accuracy: 0.828125
validation_loss: 0.5110050439834595
validation_accuracy: 0.83984375
validation_loss: 0.42957621812820435
validation_accuracy: 0.84375
validation_loss: 0.4200817942619324
validation_accuracy: 0.875
validation_loss: 0.4959960877895355
validation_accuracy: 0.84765625
validation_loss: 0.3755935728549957
validation_accuracy: 0.86328125
validation_loss: 0.5142441391944885
validation_accuracy: 0.81640625
validation_loss: 0.4871975779533386
validation_accuracy: 0.8359375
validation_loss: 0.6419984102249146
validation_accuracy: 0.77734375
validation_loss: 0.6058152318000793
validation_accuracy: 0.77734375
validation_loss: 0.5530797243118286
validation_accuracy: 0.81640625
validation_loss: 0.497231662273407
validation_accuracy: 0.8359375
validation_loss: 0.53299880027771
validation_accuracy: 0.8359375
validation_loss: 0.48878663778305054
validation_accuracy: 0.82421875
validation_loss: 0.3422160744667053
validation_accuracy: 0.875
validation_loss: 0.5252846479415894
validation_accuracy: 0.80859375
validation_loss: 0.5829900503158569
validation_accuracy: 0.80078125
validation_loss: 0.562798023223877
validation_accuracy: 0.828125
validation_loss: 0.6226310133934021
validation_accuracy: 0.79296875
validation_loss: 0.4923482835292816
validation_accuracy: 0.8203125
validation_loss: 0.4642239212989807
validation_accuracy: 0.83203125
validation_loss: 0.45881521701812744
validation_accuracy: 0.81640625
validation_loss: 0.5803278684616089
validation_accuracy: 0.78515625
validation_loss: 0.5287522077560425
validation_accuracy: 0.82421875
validation_loss: 0.457011878490448
validation_accuracy: 0.80078125
validation_loss: 0.48005956411361694
validation_accuracy: 0.83984375
validation_loss: 0.4280717074871063
validation_accuracy: 0.8515625
validation_loss: 0.4941827654838562
validation_accuracy: 0.8046875
validation_loss: 0.5359408855438232
validation_accuracy: 0.80859375
validation_loss: 0.46255382895469666
validation_accuracy: 0.8515625
validation_loss: 0.47341087460517883
validation_accuracy: 0.83203125
validation_loss: 0.5734344124794006
validation_accuracy: 0.79296875
validation_loss: 0.5036334991455078
validation_accuracy: 0.828125
validation_loss: 0.450465589761734
validation_accuracy: 0.83203125
validation_loss: 0.5421580076217651
validation_accuracy: 0.80078125
validation_loss: 0.4362790584564209
validation_accuracy: 0.859375
validation_loss: 0.3240131139755249
validation_accuracy: 0.8125
epoch 8/15
training_loss: 0.5202217102050781
training_loss: 0.44177624583244324
training_loss: 0.43262481689453125
training_loss: 0.5254263281822205
training_loss: 0.4067385792732239
training_loss: 0.4992803931236267
training_loss: 0.4334452152252197
training_loss: 0.4421461224555969
training_loss: 0.47493264079093933
training_loss: 0.453166663646698
training_loss: 0.44730955362319946
training_loss: 0.4733005464076996
training_loss: 0.38820233941078186
training_loss: 0.42675068974494934
training_loss: 0.45879507064819336
training_loss: 0.4076913595199585
training_loss: 0.3580947816371918
training_loss: 0.49140602350234985
training_loss: 0.4699830114841461
training_loss: 0.4248272478580475
training_loss: 0.4943998157978058
training_loss: 0.574298083782196
training_loss: 0.49666911363601685
training_loss: 0.47637808322906494
training_loss: 0.4815198481082916
training_loss: 0.45421287417411804
training_loss: 0.4035820960998535
training_loss: 0.4253333508968353
training_loss: 0.46259140968322754
training_loss: 0.3938228487968445
training_loss: 0.4606092572212219
training_loss: 0.4577431380748749
training_loss: 0.45289596915245056
training_loss: 0.5720994472503662
training_loss: 0.5777357220649719
training_loss: 0.5559066534042358
training_loss: 0.3734015226364136
training_loss: 0.5037145018577576
training_loss: 0.40046223998069763
training_loss: 0.4889671504497528
training_loss: 0.4554844796657562
training_loss: 0.4410788118839264
training_loss: 0.4190561771392822
training_loss: 0.47890061140060425
training_loss: 0.39957648515701294
training_loss: 0.4314955472946167
training_loss: 0.38449305295944214
training_loss: 0.42438438534736633
training_loss: 0.4927135407924652
training_loss: 0.42928028106689453
training_loss: 0.43373560905456543
training_loss: 0.4159398674964905
training_loss: 0.44896647334098816
training_loss: 0.47702887654304504
training_loss: 0.507811427116394
training_loss: 0.4186743497848511
training_loss: 0.43959078192710876
training_loss: 0.3940615952014923
training_loss: 0.509687066078186
training_loss: 0.4574117958545685
training_loss: 0.4118586480617523
training_loss: 0.34080809354782104
training_loss: 0.5265203714370728
training_loss: 0.3830917477607727
training_loss: 0.6457306146621704
training_loss: 0.5255991220474243
training_loss: 0.37942349910736084
training_loss: 0.48122304677963257
training_loss: 0.48641204833984375
training_loss: 0.4181894063949585
training_loss: 0.42224782705307007
training_loss: 0.5121383666992188
training_loss: 0.31710708141326904
training_loss: 0.5337433218955994
training_loss: 0.36209097504615784
training_loss: 0.4006015360355377
training_loss: 0.49087655544281006
training_loss: 0.47711244225502014
training_loss: 0.43846195936203003
training_loss: 0.44548675417900085
training_loss: 0.4296506941318512
training_loss: 0.4561674892902374
training_loss: 0.3679383099079132
training_loss: 0.5495896339416504
training_loss: 0.5080997347831726
training_loss: 0.3977601230144501
training_loss: 0.39012610912323
training_loss: 0.4724358916282654
training_loss: 0.4513248801231384
training_loss: 0.4585816264152527
training_loss: 0.39350372552871704
training_loss: 0.4395672082901001
training_loss: 0.4797669053077698
training_loss: 0.5090684294700623
training_loss: 0.4950493276119232
training_loss: 0.47153669595718384
training_loss: 0.521960973739624
training_loss: 0.45716848969459534
training_loss: 0.4582549035549164
training_loss: 0.46544066071510315
training_loss: 0.46416425704956055
training_loss: 0.38617926836013794
training_loss: 0.475697785615921
training_loss: 0.37344852089881897
training_loss: 0.5704358816146851
training_loss: 0.38249632716178894
training_loss: 0.47499778866767883
training_loss: 0.3310108780860901
training_loss: 0.4734024405479431
training_loss: 0.4744350016117096
training_loss: 0.38284358382225037
training_loss: 0.507550060749054
training_loss: 0.3496376872062683
training_loss: 0.43537503480911255
training_loss: 0.4145134389400482
training_loss: 0.5505815744400024
training_loss: 0.5501262545585632
training_loss: 0.5062404274940491
training_loss: 0.4168033003807068
training_loss: 0.368407666683197
training_loss: 0.411888986825943
training_loss: 0.4100300073623657
training_loss: 0.3833310306072235
training_loss: 0.44985973834991455
training_loss: 0.4597509801387787
training_loss: 0.4699104428291321
training_loss: 0.4284038245677948
training_loss: 0.4499354064464569
training_loss: 0.5355815887451172
training_loss: 0.5188639760017395
training_loss: 0.4996073246002197
training_loss: 0.4312977194786072
training_loss: 0.4438539743423462
training_loss: 0.44939473271369934
training_loss: 0.43470802903175354
training_loss: 0.3807299733161926
training_loss: 0.4326183795928955
training_loss: 0.49047914147377014
training_loss: 0.48173052072525024
training_loss: 0.47750845551490784
training_loss: 0.46417778730392456
training_loss: 0.41472944617271423
training_loss: 0.507697343826294
training_loss: 0.528914749622345
training_loss: 0.41399797797203064
training_loss: 0.399492084980011
training_loss: 0.4504373371601105
training_loss: 0.40511471033096313
training_loss: 0.43090325593948364
training_loss: 0.3971940875053406
training_loss: 0.3960248827934265
training_loss: 0.4510781764984131
training_loss: 0.5609567165374756
training_loss: 0.5409545302391052
training_loss: 0.3677513003349304
training_loss: 0.4478777050971985
training_loss: 0.43752098083496094
training_loss: 0.5453251600265503
training_loss: 0.44009411334991455
training_loss: 0.419533908367157
training_loss: 0.4602797329425812
training_loss: 0.47205349802970886
training_loss: 0.4347972869873047
training_loss: 0.41142740845680237
training_loss: 0.5083647966384888
training_loss: 0.44418448209762573
training_loss: 0.4596044421195984
training_loss: 0.47447389364242554
training_loss: 0.4950946867465973
training_loss: 0.47837764024734497
training_loss: 0.4602050483226776
training_loss: 0.41868701577186584
training_loss: 0.4208465814590454
training_loss: 0.44484198093414307
training_loss: 0.45029598474502563
training_loss: 0.4386124908924103
training_loss: 0.492290735244751
training_loss: 0.4203113317489624
training_loss: 0.33546188473701477
training_loss: 0.4063614010810852
training_loss: 0.4215555191040039
training_loss: 0.5341858863830566
training_loss: 0.38260239362716675
training_loss: 0.5006935000419617
training_loss: 0.47915327548980713
training_loss: 0.42727863788604736
training_loss: 0.4792880117893219
training_loss: 0.437446266412735
training_loss: 0.43085911870002747
training_loss: 0.39830201864242554
training_loss: 0.42952579259872437
training_loss: 0.49268704652786255
training_loss: 0.4564824104309082
training_loss: 0.4369248151779175
training_loss: 0.39989572763442993
training_loss: 0.5470335483551025
training_loss: 0.41581523418426514
training_loss: 0.33307889103889465
training_loss: 0.45250651240348816
training_loss: 0.4559237062931061
training_loss: 0.45774561166763306
training_loss: 0.411456823348999
training_loss: 0.5542706251144409
training_loss: 0.42136600613594055
training_loss: 0.4772208333015442
training_loss: 0.43089863657951355
training_loss: 0.35274428129196167
training_loss: 0.4454033076763153
training_loss: 0.4715820550918579
training_loss: 0.41100841760635376
training_loss: 0.4888104796409607
training_loss: 0.4553106725215912
training_loss: 0.42656588554382324
training_loss: 0.5095547437667847
training_loss: 0.5418940186500549
training_loss: 0.4664795398712158
training_loss: 0.44768226146698
training_loss: 0.5015605092048645
training_loss: 0.40651607513427734
training_loss: 0.4878227114677429
training_loss: 0.4554547965526581
training_loss: 0.43372055888175964
training_loss: 0.4409812390804291
training_loss: 0.4620971083641052
training_loss: 0.4519771337509155
training_loss: 0.41277700662612915
training_loss: 0.4406111538410187
training_loss: 0.46442344784736633
training_loss: 0.4936183989048004
training_loss: 0.37701016664505005
training_loss: 0.5401578545570374
training_loss: 0.3841811418533325
training_loss: 0.48363807797431946
training_loss: 0.43938174843788147
training_loss: 0.5273117423057556
validation_loss: 0.47523537278175354
validation_accuracy: 0.84765625
validation_loss: 0.48202112317085266
validation_accuracy: 0.83984375
validation_loss: 0.5663615465164185
validation_accuracy: 0.82421875
validation_loss: 0.47974228858947754
validation_accuracy: 0.84765625
validation_loss: 0.5130211710929871
validation_accuracy: 0.8046875
validation_loss: 0.4712958335876465
validation_accuracy: 0.83203125
validation_loss: 0.44943368434906006
validation_accuracy: 0.82421875
validation_loss: 0.5274613499641418
validation_accuracy: 0.82421875
validation_loss: 0.4049668312072754
validation_accuracy: 0.84375
validation_loss: 0.4997369647026062
validation_accuracy: 0.83203125
validation_loss: 0.49508732557296753
validation_accuracy: 0.83203125
validation_loss: 0.6153079867362976
validation_accuracy: 0.79296875
validation_loss: 0.6439411640167236
validation_accuracy: 0.765625
validation_loss: 0.5775326490402222
validation_accuracy: 0.80078125
validation_loss: 0.4976324439048767
validation_accuracy: 0.828125
validation_loss: 0.5337985157966614
validation_accuracy: 0.80859375
validation_loss: 0.5131099224090576
validation_accuracy: 0.80859375
validation_loss: 0.34774839878082275
validation_accuracy: 0.87890625
validation_loss: 0.5773990750312805
validation_accuracy: 0.7890625
validation_loss: 0.5929076671600342
validation_accuracy: 0.78515625
validation_loss: 0.5684256553649902
validation_accuracy: 0.7890625
validation_loss: 0.6075685024261475
validation_accuracy: 0.796875
validation_loss: 0.5368270874023438
validation_accuracy: 0.8046875
validation_loss: 0.46052396297454834
validation_accuracy: 0.8203125
validation_loss: 0.4503661096096039
validation_accuracy: 0.8125
validation_loss: 0.5808277130126953
validation_accuracy: 0.8203125
validation_loss: 0.5366321802139282
validation_accuracy: 0.83203125
validation_loss: 0.47099289298057556
validation_accuracy: 0.7890625
validation_loss: 0.48808541893959045
validation_accuracy: 0.83203125
validation_loss: 0.4481276869773865
validation_accuracy: 0.828125
validation_loss: 0.47980833053588867
validation_accuracy: 0.82421875
validation_loss: 0.5450125932693481
validation_accuracy: 0.8046875
validation_loss: 0.4253478944301605
validation_accuracy: 0.85546875
validation_loss: 0.5103416442871094
validation_accuracy: 0.8203125
validation_loss: 0.5704218149185181
validation_accuracy: 0.796875
validation_loss: 0.4739510118961334
validation_accuracy: 0.828125
validation_loss: 0.4620475172996521
validation_accuracy: 0.80859375
validation_loss: 0.5531854033470154
validation_accuracy: 0.8125
validation_loss: 0.43286988139152527
validation_accuracy: 0.84375
validation_loss: 0.34143954515457153
validation_accuracy: 0.875
epoch 9/15
training_loss: 0.38400179147720337
training_loss: 0.5237168669700623
training_loss: 0.35165348649024963
training_loss: 0.4574149250984192
training_loss: 0.476342111825943
training_loss: 0.47703245282173157
training_loss: 0.47663652896881104
training_loss: 0.4047183394432068
training_loss: 0.44511309266090393
training_loss: 0.49783819913864136
training_loss: 0.37999391555786133
training_loss: 0.3860577940940857
training_loss: 0.42131325602531433
training_loss: 0.3335098326206207
training_loss: 0.4260692298412323
training_loss: 0.4297822117805481
training_loss: 0.4029310345649719
training_loss: 0.45093393325805664
training_loss: 0.4329608082771301
training_loss: 0.5777710676193237
training_loss: 0.3948197364807129
training_loss: 0.5541783571243286
training_loss: 0.490044504404068
training_loss: 0.5278180241584778
training_loss: 0.42123672366142273
training_loss: 0.5076656341552734
training_loss: 0.382617712020874
training_loss: 0.3948054611682892
training_loss: 0.5108065605163574
training_loss: 0.4631439745426178
training_loss: 0.39665329456329346
training_loss: 0.3672071695327759
training_loss: 0.39251118898391724
training_loss: 0.4198772609233856
training_loss: 0.46968144178390503
training_loss: 0.4508070945739746
training_loss: 0.44457173347473145
training_loss: 0.38351404666900635
training_loss: 0.48463794589042664
training_loss: 0.38441866636276245
training_loss: 0.4140903353691101
training_loss: 0.49217328429222107
training_loss: 0.5667492747306824
training_loss: 0.5283520221710205
training_loss: 0.4537931978702545
training_loss: 0.4669160544872284
training_loss: 0.4864638149738312
training_loss: 0.3628813326358795
training_loss: 0.4823954999446869
training_loss: 0.6044845581054688
training_loss: 0.4737520217895508
training_loss: 0.42356014251708984
training_loss: 0.41572341322898865
training_loss: 0.5775552988052368
training_loss: 0.44368261098861694
training_loss: 0.47553491592407227
training_loss: 0.44297122955322266
training_loss: 0.467898964881897
training_loss: 0.4530695974826813
training_loss: 0.43392160534858704
training_loss: 0.5097697973251343
training_loss: 0.39448004961013794
training_loss: 0.44521403312683105
training_loss: 0.4995192885398865
training_loss: 0.48738691210746765
training_loss: 0.5083870887756348
training_loss: 0.4402191638946533
training_loss: 0.4277040362358093
training_loss: 0.4299784302711487
training_loss: 0.4703230559825897
training_loss: 0.3929581940174103
training_loss: 0.37729933857917786
training_loss: 0.5248827338218689
training_loss: 0.38429051637649536
training_loss: 0.37019017338752747
training_loss: 0.4610653817653656
training_loss: 0.4129251539707184
training_loss: 0.40119820833206177
training_loss: 0.493047833442688
training_loss: 0.42572152614593506
training_loss: 0.4202994704246521
training_loss: 0.438993901014328
training_loss: 0.609784722328186
training_loss: 0.502133846282959
training_loss: 0.4959266483783722
training_loss: 0.4371075928211212
training_loss: 0.3272961974143982
training_loss: 0.4451395273208618
training_loss: 0.46819230914115906
training_loss: 0.3982180953025818
training_loss: 0.46120429039001465
training_loss: 0.405574768781662
training_loss: 0.39993664622306824
training_loss: 0.4214003384113312
training_loss: 0.46111151576042175
training_loss: 0.43279123306274414
training_loss: 0.3924884498119354
training_loss: 0.4597631096839905
training_loss: 0.44333332777023315
training_loss: 0.4224337339401245
training_loss: 0.5087106227874756
training_loss: 0.48116612434387207
training_loss: 0.5433935523033142
training_loss: 0.4904412031173706
training_loss: 0.43492045998573303
training_loss: 0.40613049268722534
training_loss: 0.44450265169143677
training_loss: 0.4945524036884308
training_loss: 0.4548502564430237
training_loss: 0.46607112884521484
training_loss: 0.5106092095375061
training_loss: 0.3753730356693268
training_loss: 0.5000012516975403
training_loss: 0.5428047180175781
training_loss: 0.5363861322402954
training_loss: 0.4633314907550812
training_loss: 0.41782552003860474
training_loss: 0.3871577978134155
training_loss: 0.4679473638534546
training_loss: 0.4624934196472168
training_loss: 0.48193052411079407
training_loss: 0.42386379837989807
training_loss: 0.40585824847221375
training_loss: 0.4266066551208496
training_loss: 0.5053523182868958
training_loss: 0.49906474351882935
training_loss: 0.37631481885910034
training_loss: 0.41525545716285706
training_loss: 0.5043665766716003
training_loss: 0.4691134989261627
training_loss: 0.44524502754211426
training_loss: 0.4856024384498596
training_loss: 0.4125523269176483
training_loss: 0.37900564074516296
training_loss: 0.464988648891449
training_loss: 0.3916023075580597
training_loss: 0.4584366977214813
training_loss: 0.4508669674396515
training_loss: 0.3782373070716858
training_loss: 0.4709838032722473
training_loss: 0.3721735179424286
training_loss: 0.4196535646915436
training_loss: 0.3450013995170593
training_loss: 0.5330974459648132
training_loss: 0.4164581894874573
training_loss: 0.3673167824745178
training_loss: 0.41034814715385437
training_loss: 0.4264707863330841
training_loss: 0.4112423360347748
training_loss: 0.4100172817707062
training_loss: 0.52165687084198
training_loss: 0.3875102698802948
training_loss: 0.41466277837753296
training_loss: 0.4786992073059082
training_loss: 0.4387386739253998
training_loss: 0.36649996042251587
training_loss: 0.43934279680252075
training_loss: 0.40549135208129883
training_loss: 0.3708673417568207
training_loss: 0.39923155307769775
training_loss: 0.43932145833969116
training_loss: 0.3486478924751282
training_loss: 0.5023314356803894
training_loss: 0.4118494391441345
training_loss: 0.5073561072349548
training_loss: 0.35686352849006653
training_loss: 0.4819304943084717
training_loss: 0.4085250496864319
training_loss: 0.4256764054298401
training_loss: 0.4800346791744232
training_loss: 0.40736645460128784
training_loss: 0.5065246820449829
training_loss: 0.4320353865623474
training_loss: 0.41836807131767273
training_loss: 0.527916431427002
training_loss: 0.4546680450439453
training_loss: 0.4825688600540161
training_loss: 0.4430086016654968
training_loss: 0.4075393080711365
training_loss: 0.5033748149871826
training_loss: 0.45130276679992676
training_loss: 0.46634551882743835
training_loss: 0.468136191368103
training_loss: 0.4229394197463989
training_loss: 0.45228350162506104
training_loss: 0.40066516399383545
training_loss: 0.4226025938987732
training_loss: 0.4275414049625397
training_loss: 0.4499426484107971
training_loss: 0.45936518907546997
training_loss: 0.41737234592437744
training_loss: 0.4709412455558777
training_loss: 0.3883308470249176
training_loss: 0.5620409846305847
training_loss: 0.3434661626815796
training_loss: 0.41645359992980957
training_loss: 0.4310145378112793
training_loss: 0.48573601245880127
training_loss: 0.5251443982124329
training_loss: 0.5308418869972229
training_loss: 0.40071433782577515
training_loss: 0.36761412024497986
training_loss: 0.4111841917037964
training_loss: 0.36873483657836914
training_loss: 0.394513338804245
training_loss: 0.40929707884788513
training_loss: 0.4104633629322052
training_loss: 0.447150856256485
training_loss: 0.40927600860595703
training_loss: 0.48952966928482056
training_loss: 0.36228469014167786
training_loss: 0.5054171085357666
training_loss: 0.4277113974094391
training_loss: 0.4386873245239258
training_loss: 0.47576865553855896
training_loss: 0.42831286787986755
training_loss: 0.4311191439628601
training_loss: 0.41000279784202576
training_loss: 0.4946860671043396
training_loss: 0.49002671241760254
training_loss: 0.4712325632572174
training_loss: 0.3976387083530426
training_loss: 0.47289666533470154
training_loss: 0.6221810579299927
training_loss: 0.4468909800052643
training_loss: 0.49560821056365967
training_loss: 0.48562443256378174
training_loss: 0.3591441214084625
training_loss: 0.48111462593078613
training_loss: 0.4685935080051422
training_loss: 0.466152548789978
training_loss: 0.4150201082229614
training_loss: 0.5377314686775208
training_loss: 0.567875862121582
training_loss: 0.45707234740257263
validation_loss: 0.40208354592323303
validation_accuracy: 0.84765625
validation_loss: 0.43130239844322205
validation_accuracy: 0.84375
validation_loss: 0.5577524304389954
validation_accuracy: 0.8203125
validation_loss: 0.4571796655654907
validation_accuracy: 0.84765625
validation_loss: 0.48686811327934265
validation_accuracy: 0.84375
validation_loss: 0.4204930067062378
validation_accuracy: 0.85546875
validation_loss: 0.40902137756347656
validation_accuracy: 0.8828125
validation_loss: 0.4884212911128998
validation_accuracy: 0.84765625
validation_loss: 0.3614049553871155
validation_accuracy: 0.85546875
validation_loss: 0.49084681272506714
validation_accuracy: 0.81640625
validation_loss: 0.4773792028427124
validation_accuracy: 0.81640625
validation_loss: 0.6184308528900146
validation_accuracy: 0.78125
validation_loss: 0.5985572338104248
validation_accuracy: 0.7890625
validation_loss: 0.5541032552719116
validation_accuracy: 0.8125
validation_loss: 0.4825500547885895
validation_accuracy: 0.828125
validation_loss: 0.518750786781311
validation_accuracy: 0.828125
validation_loss: 0.48180580139160156
validation_accuracy: 0.828125
validation_loss: 0.31950095295906067
validation_accuracy: 0.88671875
validation_loss: 0.5238998532295227
validation_accuracy: 0.8203125
validation_loss: 0.5665169954299927
validation_accuracy: 0.7890625
validation_loss: 0.5521360039710999
validation_accuracy: 0.8359375
validation_loss: 0.5972439646720886
validation_accuracy: 0.80078125
validation_loss: 0.47091901302337646
validation_accuracy: 0.8203125
validation_loss: 0.44452187418937683
validation_accuracy: 0.83984375
validation_loss: 0.4274417757987976
validation_accuracy: 0.84375
validation_loss: 0.5624836683273315
validation_accuracy: 0.7890625
validation_loss: 0.5202003121376038
validation_accuracy: 0.83203125
validation_loss: 0.4346008598804474
validation_accuracy: 0.828125
validation_loss: 0.44586461782455444
validation_accuracy: 0.84375
validation_loss: 0.41020965576171875
validation_accuracy: 0.86328125
validation_loss: 0.4642772972583771
validation_accuracy: 0.828125
validation_loss: 0.5196340084075928
validation_accuracy: 0.78515625
validation_loss: 0.4377999007701874
validation_accuracy: 0.84375
validation_loss: 0.47209781408309937
validation_accuracy: 0.828125
validation_loss: 0.5474277138710022
validation_accuracy: 0.796875
validation_loss: 0.47231823205947876
validation_accuracy: 0.8203125
validation_loss: 0.4237237870693207
validation_accuracy: 0.8359375
validation_loss: 0.5364968180656433
validation_accuracy: 0.80078125
validation_loss: 0.41395875811576843
validation_accuracy: 0.8828125
validation_loss: 0.32664787769317627
validation_accuracy: 0.875
epoch 10/15
training_loss: 0.4338582158088684
training_loss: 0.4606218934059143
training_loss: 0.423695832490921
training_loss: 0.44943100214004517
training_loss: 0.4193524122238159
training_loss: 0.42409607768058777
training_loss: 0.4660717844963074
training_loss: 0.429675817489624
training_loss: 0.42181456089019775
training_loss: 0.4545426666736603
training_loss: 0.47654980421066284
training_loss: 0.5067241787910461
training_loss: 0.3803293704986572
training_loss: 0.47083669900894165
training_loss: 0.42376187443733215
training_loss: 0.3954077363014221
training_loss: 0.5174511075019836
training_loss: 0.3708345890045166
training_loss: 0.5765120983123779
training_loss: 0.557344377040863
training_loss: 0.437134325504303
training_loss: 0.39375782012939453
training_loss: 0.37102872133255005
training_loss: 0.400777667760849
training_loss: 0.4694119393825531
training_loss: 0.3654162883758545
training_loss: 0.4634210467338562
training_loss: 0.37218397855758667
training_loss: 0.41344964504241943
training_loss: 0.4738101363182068
training_loss: 0.5887623429298401
training_loss: 0.46942824125289917
training_loss: 0.3979721665382385
training_loss: 0.3831919729709625
training_loss: 0.3855336010456085
training_loss: 0.4393596053123474
training_loss: 0.4270256757736206
training_loss: 0.3377922475337982
training_loss: 0.4238172769546509
training_loss: 0.4175899028778076
training_loss: 0.43737736344337463
training_loss: 0.5399761199951172
training_loss: 0.38604745268821716
training_loss: 0.4420454502105713
training_loss: 0.4913235902786255
training_loss: 0.3971558213233948
training_loss: 0.3994777798652649
training_loss: 0.4402269124984741
training_loss: 0.4114952087402344
training_loss: 0.4011736810207367
training_loss: 0.45209643244743347
training_loss: 0.4224538803100586
training_loss: 0.4639195203781128
training_loss: 0.4061278700828552
training_loss: 0.41217494010925293
training_loss: 0.5241150856018066
training_loss: 0.4632948935031891
training_loss: 0.44759243726730347
training_loss: 0.46966445446014404
training_loss: 0.5462955832481384
training_loss: 0.35409364104270935
training_loss: 0.4715396761894226
training_loss: 0.5262977480888367
training_loss: 0.4090411067008972
training_loss: 0.4729023575782776
training_loss: 0.33461177349090576
training_loss: 0.4142795205116272
training_loss: 0.4741426408290863
training_loss: 0.5090811848640442
training_loss: 0.36044013500213623
training_loss: 0.42265960574150085
training_loss: 0.45751550793647766
training_loss: 0.471863329410553
training_loss: 0.5143019556999207
training_loss: 0.4113658368587494
training_loss: 0.4414612054824829
training_loss: 0.3213376998901367
training_loss: 0.4346112012863159
training_loss: 0.4558192789554596
training_loss: 0.5285987257957458
training_loss: 0.4960798919200897
training_loss: 0.5008974075317383
training_loss: 0.4658612608909607
training_loss: 0.43087247014045715
training_loss: 0.4278489351272583
training_loss: 0.41788628697395325
training_loss: 0.5053532123565674
training_loss: 0.3179091811180115
training_loss: 0.4538959264755249
training_loss: 0.41750991344451904
training_loss: 0.44487398862838745
training_loss: 0.4845302402973175
training_loss: 0.4153100252151489
training_loss: 0.4009222388267517
training_loss: 0.4191221594810486
training_loss: 0.4038218557834625
training_loss: 0.4049782156944275
training_loss: 0.49386361241340637
training_loss: 0.39104071259498596
training_loss: 0.4044879078865051
training_loss: 0.4081678092479706
training_loss: 0.41075408458709717
training_loss: 0.5168426632881165
training_loss: 0.4742783308029175
training_loss: 0.4040980935096741
training_loss: 0.4227629005908966
training_loss: 0.37582656741142273
training_loss: 0.4016015827655792
training_loss: 0.4198251962661743
training_loss: 0.33311474323272705
training_loss: 0.3910558223724365
training_loss: 0.39698243141174316
training_loss: 0.46237871050834656
training_loss: 0.47695082426071167
training_loss: 0.4129023253917694
training_loss: 0.41621461510658264
training_loss: 0.4341641068458557
training_loss: 0.451295405626297
training_loss: 0.37932825088500977
training_loss: 0.40332263708114624
training_loss: 0.4408113658428192
training_loss: 0.5155079960823059
training_loss: 0.415121853351593
training_loss: 0.5492690801620483
training_loss: 0.40184035897254944
training_loss: 0.35435721278190613
training_loss: 0.47876331210136414
training_loss: 0.51085364818573
training_loss: 0.4149347245693207
training_loss: 0.411859929561615
training_loss: 0.36996448040008545
training_loss: 0.4704553782939911
training_loss: 0.42681804299354553
training_loss: 0.48166966438293457
training_loss: 0.4129725694656372
training_loss: 0.3797990083694458
training_loss: 0.5175693035125732
training_loss: 0.3864043354988098
training_loss: 0.43857046961784363
training_loss: 0.5183852314949036
training_loss: 0.501541256904602
training_loss: 0.4270060062408447
training_loss: 0.5063122510910034
training_loss: 0.4215904176235199
training_loss: 0.4061817228794098
training_loss: 0.44984903931617737
training_loss: 0.40940678119659424
training_loss: 0.3598025441169739
training_loss: 0.4106818735599518
training_loss: 0.5118107795715332
training_loss: 0.40931668877601624
training_loss: 0.42118263244628906
training_loss: 0.47379806637763977
training_loss: 0.5391288995742798
training_loss: 0.4508589208126068
training_loss: 0.4545230269432068
training_loss: 0.49439072608947754
training_loss: 0.4140470325946808
training_loss: 0.3923342525959015
training_loss: 0.4708698093891144
training_loss: 0.4544413387775421
training_loss: 0.41425246000289917
training_loss: 0.520366907119751
training_loss: 0.5101180076599121
training_loss: 0.3985635042190552
training_loss: 0.44795355200767517
training_loss: 0.3895752727985382
training_loss: 0.5706712603569031
training_loss: 0.45823001861572266
training_loss: 0.521091878414154
training_loss: 0.4574245810508728
training_loss: 0.47366979718208313
training_loss: 0.46890535950660706
training_loss: 0.4184724688529968
training_loss: 0.46086379885673523
training_loss: 0.43612056970596313
training_loss: 0.41096240282058716
training_loss: 0.42663219571113586
training_loss: 0.4954099655151367
training_loss: 0.4415614604949951
training_loss: 0.40226060152053833
training_loss: 0.3809139132499695
training_loss: 0.46049582958221436
training_loss: 0.43872925639152527
training_loss: 0.38992440700531006
training_loss: 0.4829197824001312
training_loss: 0.34960365295410156
training_loss: 0.5423057675361633
training_loss: 0.43500983715057373
training_loss: 0.5148758888244629
training_loss: 0.42694008350372314
training_loss: 0.4835110306739807
training_loss: 0.4864038825035095
training_loss: 0.52345210313797
training_loss: 0.48967111110687256
training_loss: 0.3551734387874603
training_loss: 0.4553392231464386
training_loss: 0.5483822226524353
training_loss: 0.43512189388275146
training_loss: 0.46933844685554504
training_loss: 0.5055491328239441
training_loss: 0.3824896812438965
training_loss: 0.47362881898880005
training_loss: 0.5613532066345215
training_loss: 0.4410761892795563
training_loss: 0.44314029812812805
training_loss: 0.47433918714523315
training_loss: 0.4924992024898529
training_loss: 0.45191603899002075
training_loss: 0.42059484124183655
training_loss: 0.4096860885620117
training_loss: 0.35551705956459045
training_loss: 0.4595763385295868
training_loss: 0.35688185691833496
training_loss: 0.3734216094017029
training_loss: 0.4283801317214966
training_loss: 0.4670667350292206
training_loss: 0.4158211052417755
training_loss: 0.4297865331172943
training_loss: 0.3870236277580261
training_loss: 0.4029581546783447
training_loss: 0.43648290634155273
training_loss: 0.4926014542579651
training_loss: 0.4764050245285034
training_loss: 0.4169292151927948
training_loss: 0.4510044455528259
training_loss: 0.5475680828094482
training_loss: 0.5239931344985962
training_loss: 0.472897469997406
training_loss: 0.39293205738067627
training_loss: 0.3940374553203583
training_loss: 0.429269015789032
training_loss: 0.5545853972434998
training_loss: 0.44866734743118286
training_loss: 0.5135019421577454
validation_loss: 0.4079201817512512
validation_accuracy: 0.859375
validation_loss: 0.42706915736198425
validation_accuracy: 0.8515625
validation_loss: 0.5512765645980835
validation_accuracy: 0.8203125
validation_loss: 0.4330165684223175
validation_accuracy: 0.84765625
validation_loss: 0.4685228765010834
validation_accuracy: 0.8359375
validation_loss: 0.4277456998825073
validation_accuracy: 0.84375
validation_loss: 0.41886067390441895
validation_accuracy: 0.875
validation_loss: 0.49049103260040283
validation_accuracy: 0.8515625
validation_loss: 0.3618125319480896
validation_accuracy: 0.859375
validation_loss: 0.4839034080505371
validation_accuracy: 0.8203125
validation_loss: 0.4398966133594513
validation_accuracy: 0.84765625
validation_loss: 0.6143949627876282
validation_accuracy: 0.796875
validation_loss: 0.5852155685424805
validation_accuracy: 0.796875
validation_loss: 0.550378143787384
validation_accuracy: 0.80859375
validation_loss: 0.4680412709712982
validation_accuracy: 0.83984375
validation_loss: 0.5114047527313232
validation_accuracy: 0.8515625
validation_loss: 0.4822315573692322
validation_accuracy: 0.828125
validation_loss: 0.30396509170532227
validation_accuracy: 0.8984375
validation_loss: 0.5437002182006836
validation_accuracy: 0.80859375
validation_loss: 0.5588250756263733
validation_accuracy: 0.80078125
validation_loss: 0.5235246419906616
validation_accuracy: 0.84375
validation_loss: 0.5945616364479065
validation_accuracy: 0.8046875
validation_loss: 0.48755723237991333
validation_accuracy: 0.81640625
validation_loss: 0.44518929719924927
validation_accuracy: 0.8125
validation_loss: 0.4263313114643097
validation_accuracy: 0.84375
validation_loss: 0.558786928653717
validation_accuracy: 0.79296875
validation_loss: 0.5043773055076599
validation_accuracy: 0.83984375
validation_loss: 0.4439827799797058
validation_accuracy: 0.80859375
validation_loss: 0.4511086642742157
validation_accuracy: 0.84765625
validation_loss: 0.4033181667327881
validation_accuracy: 0.8515625
validation_loss: 0.4427269697189331
validation_accuracy: 0.83203125
validation_loss: 0.5110712647438049
validation_accuracy: 0.80078125
validation_loss: 0.42086005210876465
validation_accuracy: 0.86328125
validation_loss: 0.45937979221343994
validation_accuracy: 0.84375
validation_loss: 0.5289515852928162
validation_accuracy: 0.796875
validation_loss: 0.4592646360397339
validation_accuracy: 0.84765625
validation_loss: 0.423676460981369
validation_accuracy: 0.8359375
validation_loss: 0.5298689603805542
validation_accuracy: 0.83203125
validation_loss: 0.398689329624176
validation_accuracy: 0.86328125
validation_loss: 0.32935094833374023
validation_accuracy: 0.875
epoch 11/15
training_loss: 0.47217047214508057
training_loss: 0.4411323666572571
training_loss: 0.3487098515033722
training_loss: 0.4082351624965668
training_loss: 0.32759425044059753
training_loss: 0.41864436864852905
training_loss: 0.4848628044128418
training_loss: 0.4510045647621155
training_loss: 0.4916732907295227
training_loss: 0.4389905333518982
training_loss: 0.4294697344303131
training_loss: 0.5604898929595947
training_loss: 0.5184462666511536
training_loss: 0.4406410753726959
training_loss: 0.3792901933193207
training_loss: 0.467460960149765
training_loss: 0.4278501868247986
training_loss: 0.41967347264289856
training_loss: 0.4143851697444916
training_loss: 0.4652808606624603
training_loss: 0.39762258529663086
training_loss: 0.4063846468925476
training_loss: 0.45306578278541565
training_loss: 0.5376714468002319
training_loss: 0.38344913721084595
training_loss: 0.475902795791626
training_loss: 0.4532189965248108
training_loss: 0.4125669002532959
training_loss: 0.4569445252418518
training_loss: 0.38541412353515625
training_loss: 0.5034691095352173
training_loss: 0.3966502845287323
training_loss: 0.38728392124176025
training_loss: 0.46460404992103577
training_loss: 0.4794626832008362
training_loss: 0.4125809073448181
training_loss: 0.42380011081695557
training_loss: 0.37870705127716064
training_loss: 0.5131138563156128
training_loss: 0.39909693598747253
training_loss: 0.5432707667350769
training_loss: 0.391171395778656
training_loss: 0.4171387851238251
training_loss: 0.3931937515735626
training_loss: 0.39919954538345337
training_loss: 0.4251207113265991
training_loss: 0.49678969383239746
training_loss: 0.43522804975509644
training_loss: 0.3927076458930969
training_loss: 0.4113408327102661
training_loss: 0.4824034869670868
training_loss: 0.4157410264015198
training_loss: 0.3968004286289215
training_loss: 0.4457639753818512
training_loss: 0.467223197221756
training_loss: 0.3885965347290039
training_loss: 0.5133687853813171
training_loss: 0.46988725662231445
training_loss: 0.4196830987930298
training_loss: 0.49874043464660645
training_loss: 0.4225349724292755
training_loss: 0.447707861661911
training_loss: 0.3237588405609131
training_loss: 0.4500824809074402
training_loss: 0.4592295289039612
training_loss: 0.46860867738723755
training_loss: 0.42385515570640564
training_loss: 0.3839479088783264
training_loss: 0.3702622950077057
training_loss: 0.3729085326194763
training_loss: 0.42947033047676086
training_loss: 0.47249531745910645
training_loss: 0.36716321110725403
training_loss: 0.3983938694000244
training_loss: 0.43427348136901855
training_loss: 0.39921650290489197
training_loss: 0.5317289233207703
training_loss: 0.3938194811344147
training_loss: 0.4427958130836487
training_loss: 0.44723594188690186
training_loss: 0.4504755735397339
training_loss: 0.48053812980651855
training_loss: 0.5118311047554016
training_loss: 0.45341381430625916
training_loss: 0.43887630105018616
training_loss: 0.47782284021377563
training_loss: 0.4763549268245697
training_loss: 0.4238550662994385
training_loss: 0.44557487964630127
training_loss: 0.42191389203071594
training_loss: 0.4627971649169922
training_loss: 0.43088722229003906
training_loss: 0.46409618854522705
training_loss: 0.4156580865383148
training_loss: 0.41609370708465576
training_loss: 0.3885957896709442
training_loss: 0.41861581802368164
training_loss: 0.42218223214149475
training_loss: 0.5108948945999146
training_loss: 0.5049545168876648
training_loss: 0.4500459134578705
training_loss: 0.508330225944519
training_loss: 0.4338460862636566
training_loss: 0.40737205743789673
training_loss: 0.3893515169620514
training_loss: 0.49200546741485596
training_loss: 0.5520651936531067
training_loss: 0.4088239371776581
training_loss: 0.39807119965553284
training_loss: 0.45520836114883423
training_loss: 0.4186364412307739
training_loss: 0.4792691469192505
training_loss: 0.42101871967315674
training_loss: 0.4168495535850525
training_loss: 0.4271465539932251
training_loss: 0.41268256306648254
training_loss: 0.4704979658126831
training_loss: 0.3575427830219269
training_loss: 0.4688720107078552
training_loss: 0.47927239537239075
training_loss: 0.34988945722579956
training_loss: 0.48500871658325195
training_loss: 0.39469945430755615
training_loss: 0.349120557308197
training_loss: 0.4309440553188324
training_loss: 0.480055570602417
training_loss: 0.36449840664863586
training_loss: 0.43286216259002686
training_loss: 0.3816686272621155
training_loss: 0.43807271122932434
training_loss: 0.48028984665870667
training_loss: 0.4585105776786804
training_loss: 0.42660439014434814
training_loss: 0.47464245557785034
training_loss: 0.3873029053211212
training_loss: 0.44054684042930603
training_loss: 0.34839627146720886
training_loss: 0.3592924475669861
training_loss: 0.42528271675109863
training_loss: 0.40791991353034973
training_loss: 0.46028435230255127
training_loss: 0.44800376892089844
training_loss: 0.5103116631507874
training_loss: 0.35884732007980347
training_loss: 0.3983718454837799
training_loss: 0.4246905744075775
training_loss: 0.41588589549064636
training_loss: 0.45080822706222534
training_loss: 0.5175010561943054
training_loss: 0.4958406090736389
training_loss: 0.4582380950450897
training_loss: 0.4644750952720642
training_loss: 0.4904243052005768
training_loss: 0.44460803270339966
training_loss: 0.4986221194267273
training_loss: 0.4386640191078186
training_loss: 0.3892955780029297
training_loss: 0.45380938053131104
training_loss: 0.48388510942459106
training_loss: 0.37933850288391113
training_loss: 0.541985273361206
training_loss: 0.403328001499176
training_loss: 0.45182013511657715
training_loss: 0.4245375394821167
training_loss: 0.42689013481140137
training_loss: 0.39655017852783203
training_loss: 0.48728203773498535
training_loss: 0.37357109785079956
training_loss: 0.5440378189086914
training_loss: 0.47394412755966187
training_loss: 0.41949260234832764
training_loss: 0.4853435158729553
training_loss: 0.37628814578056335
training_loss: 0.5007854700088501
training_loss: 0.45929116010665894
training_loss: 0.3705655038356781
training_loss: 0.42432770133018494
training_loss: 0.398771733045578
training_loss: 0.40968987345695496
training_loss: 0.4825625419616699
training_loss: 0.42416542768478394
training_loss: 0.36278635263442993
training_loss: 0.36409834027290344
training_loss: 0.5427126884460449
training_loss: 0.38889992237091064
training_loss: 0.4102919101715088
training_loss: 0.5339621305465698
training_loss: 0.4643276035785675
training_loss: 0.4466233551502228
training_loss: 0.47041380405426025
training_loss: 0.542650043964386
training_loss: 0.3811153173446655
training_loss: 0.5249356627464294
training_loss: 0.5280870199203491
training_loss: 0.4711110591888428
training_loss: 0.4756644368171692
training_loss: 0.4596971273422241
training_loss: 0.43092501163482666
training_loss: 0.4689391851425171
training_loss: 0.46732568740844727
training_loss: 0.48152288794517517
training_loss: 0.43066349625587463
training_loss: 0.4225234091281891
training_loss: 0.41275542974472046
training_loss: 0.3596469461917877
training_loss: 0.3676636815071106
training_loss: 0.4051894247531891
training_loss: 0.4699048399925232
training_loss: 0.4809170663356781
training_loss: 0.526433527469635
training_loss: 0.3780226707458496
training_loss: 0.4312938451766968
training_loss: 0.479625403881073
training_loss: 0.4251677393913269
training_loss: 0.4348538815975189
training_loss: 0.46782004833221436
training_loss: 0.4373050332069397
training_loss: 0.4952051341533661
training_loss: 0.4929877817630768
training_loss: 0.4457986354827881
training_loss: 0.43352028727531433
training_loss: 0.4815727472305298
training_loss: 0.4279789626598358
training_loss: 0.3907136619091034
training_loss: 0.3863021731376648
training_loss: 0.3841150403022766
training_loss: 0.4198133945465088
training_loss: 0.3656444549560547
training_loss: 0.46511179208755493
training_loss: 0.3959973454475403
training_loss: 0.4583238363265991
training_loss: 0.4555286169052124
training_loss: 0.452995240688324
training_loss: 0.43283811211586
training_loss: 0.440946489572525
validation_loss: 0.4013787508010864
validation_accuracy: 0.86328125
validation_loss: 0.4205785393714905
validation_accuracy: 0.8515625
validation_loss: 0.5598595142364502
validation_accuracy: 0.81640625
validation_loss: 0.439211905002594
validation_accuracy: 0.84375
validation_loss: 0.47482961416244507
validation_accuracy: 0.85546875
validation_loss: 0.42696505784988403
validation_accuracy: 0.8359375
validation_loss: 0.4275661110877991
validation_accuracy: 0.88671875
validation_loss: 0.49319523572921753
validation_accuracy: 0.85546875
validation_loss: 0.3606710433959961
validation_accuracy: 0.83984375
validation_loss: 0.4822097420692444
validation_accuracy: 0.83203125
validation_loss: 0.44981932640075684
validation_accuracy: 0.83984375
validation_loss: 0.6368576288223267
validation_accuracy: 0.78515625
validation_loss: 0.594751238822937
validation_accuracy: 0.80859375
validation_loss: 0.5665422081947327
validation_accuracy: 0.79296875
validation_loss: 0.47601160407066345
validation_accuracy: 0.83984375
validation_loss: 0.5220587253570557
validation_accuracy: 0.84765625
validation_loss: 0.49263668060302734
validation_accuracy: 0.82421875
validation_loss: 0.3012754023075104
validation_accuracy: 0.89453125
validation_loss: 0.5511227250099182
validation_accuracy: 0.80859375
validation_loss: 0.5626726150512695
validation_accuracy: 0.8125
validation_loss: 0.524416983127594
validation_accuracy: 0.83984375
validation_loss: 0.6039590835571289
validation_accuracy: 0.8046875
validation_loss: 0.5040902495384216
validation_accuracy: 0.8203125
validation_loss: 0.4636337161064148
validation_accuracy: 0.8125
validation_loss: 0.4358762502670288
validation_accuracy: 0.83984375
validation_loss: 0.5633276104927063
validation_accuracy: 0.79296875
validation_loss: 0.5033615827560425
validation_accuracy: 0.83203125
validation_loss: 0.4573126435279846
validation_accuracy: 0.8046875
validation_loss: 0.46225032210350037
validation_accuracy: 0.83984375
validation_loss: 0.40149393677711487
validation_accuracy: 0.8515625
validation_loss: 0.46761175990104675
validation_accuracy: 0.83984375
validation_loss: 0.5213260054588318
validation_accuracy: 0.80078125
validation_loss: 0.43647629022598267
validation_accuracy: 0.8515625
validation_loss: 0.45198798179626465
validation_accuracy: 0.84765625
validation_loss: 0.5592703819274902
validation_accuracy: 0.78125
validation_loss: 0.4771179258823395
validation_accuracy: 0.84375
validation_loss: 0.43506288528442383
validation_accuracy: 0.8515625
validation_loss: 0.5481682419776917
validation_accuracy: 0.828125
validation_loss: 0.4079391360282898
validation_accuracy: 0.86328125
validation_loss: 0.31857767701148987
validation_accuracy: 0.9375
epoch 12/15
training_loss: 0.45962363481521606
training_loss: 0.4268801510334015
training_loss: 0.39008188247680664
training_loss: 0.41326457262039185
training_loss: 0.3518308699131012
training_loss: 0.4452578127384186
training_loss: 0.3996840715408325
training_loss: 0.39006879925727844
training_loss: 0.5137889981269836
training_loss: 0.40370655059814453
training_loss: 0.43764758110046387
training_loss: 0.34819990396499634
training_loss: 0.3847939372062683
training_loss: 0.5055316090583801
training_loss: 0.43208634853363037
training_loss: 0.3733149766921997
training_loss: 0.447564959526062
training_loss: 0.4105631113052368
training_loss: 0.5720877051353455
training_loss: 0.4273698627948761
training_loss: 0.37560856342315674
training_loss: 0.42428264021873474
training_loss: 0.4863557815551758
training_loss: 0.39778342843055725
training_loss: 0.4273685812950134
training_loss: 0.42465052008628845
training_loss: 0.45669132471084595
training_loss: 0.44728517532348633
training_loss: 0.4509275555610657
training_loss: 0.4167562425136566
training_loss: 0.38473957777023315
training_loss: 0.4961269795894623
training_loss: 0.4711114168167114
training_loss: 0.4176669120788574
training_loss: 0.4498826861381531
training_loss: 0.48115986585617065
training_loss: 0.4744960069656372
training_loss: 0.4814804196357727
training_loss: 0.52406245470047
training_loss: 0.5275643467903137
training_loss: 0.3547711968421936
training_loss: 0.45979273319244385
training_loss: 0.31850358843803406
training_loss: 0.5445942282676697
training_loss: 0.42237725853919983
training_loss: 0.3479774594306946
training_loss: 0.4088476300239563
training_loss: 0.4360044300556183
training_loss: 0.44492805004119873
training_loss: 0.3769431710243225
training_loss: 0.3914862871170044
training_loss: 0.44186729192733765
training_loss: 0.4297407567501068
training_loss: 0.446340948343277
training_loss: 0.3957631289958954
training_loss: 0.4714522361755371
training_loss: 0.39817723631858826
training_loss: 0.41025054454803467
training_loss: 0.43618226051330566
training_loss: 0.5522838234901428
training_loss: 0.36043763160705566
training_loss: 0.521467924118042
training_loss: 0.4578882157802582
training_loss: 0.49929821491241455
training_loss: 0.37570667266845703
training_loss: 0.43301934003829956
training_loss: 0.41487255692481995
training_loss: 0.3857373595237732
training_loss: 0.4529544711112976
training_loss: 0.44865602254867554
training_loss: 0.49305596947669983
training_loss: 0.438111275434494
training_loss: 0.43504196405410767
training_loss: 0.3597124218940735
training_loss: 0.45497462153434753
training_loss: 0.4372977614402771
training_loss: 0.36661583185195923
training_loss: 0.4164239764213562
training_loss: 0.32882678508758545
training_loss: 0.4489077627658844
training_loss: 0.37179142236709595
training_loss: 0.49300411343574524
training_loss: 0.3994350731372833
training_loss: 0.4468848407268524
training_loss: 0.391465961933136
training_loss: 0.49592161178588867
training_loss: 0.37766724824905396
training_loss: 0.4307200014591217
training_loss: 0.4799750745296478
training_loss: 0.4044838845729828
training_loss: 0.44343897700309753
training_loss: 0.39358246326446533
training_loss: 0.44133028388023376
training_loss: 0.357014924287796
training_loss: 0.36332109570503235
training_loss: 0.36477163434028625
training_loss: 0.40087246894836426
training_loss: 0.3786577880382538
training_loss: 0.5578569173812866
training_loss: 0.4996912479400635
training_loss: 0.4684177041053772
training_loss: 0.5146796107292175
training_loss: 0.5326144099235535
training_loss: 0.4647102653980255
training_loss: 0.6601872444152832
training_loss: 0.5431861877441406
training_loss: 0.4987470209598541
training_loss: 0.4431350827217102
training_loss: 0.3571675419807434
training_loss: 0.34030845761299133
training_loss: 0.41605719923973083
training_loss: 0.40776532888412476
training_loss: 0.402858167886734
training_loss: 0.4279436469078064
training_loss: 0.5430124998092651
training_loss: 0.42264610528945923
training_loss: 0.4057386517524719
training_loss: 0.38727667927742004
training_loss: 0.3748171627521515
training_loss: 0.4354920983314514
training_loss: 0.42433634400367737
training_loss: 0.37711331248283386
training_loss: 0.3921669125556946
training_loss: 0.41102704405784607
training_loss: 0.42437100410461426
training_loss: 0.508631706237793
training_loss: 0.39679965376853943
training_loss: 0.3973531424999237
training_loss: 0.3595467507839203
training_loss: 0.3447894752025604
training_loss: 0.37957996129989624
training_loss: 0.3634108901023865
training_loss: 0.4094407260417938
training_loss: 0.5165503621101379
training_loss: 0.4467319846153259
training_loss: 0.3813638389110565
training_loss: 0.4769577383995056
training_loss: 0.47569647431373596
training_loss: 0.4177541434764862
training_loss: 0.43133974075317383
training_loss: 0.45607003569602966
training_loss: 0.4430202543735504
training_loss: 0.4112391471862793
training_loss: 0.40856438875198364
training_loss: 0.5118591785430908
training_loss: 0.4296301603317261
training_loss: 0.4377891719341278
training_loss: 0.44633716344833374
training_loss: 0.4322628378868103
training_loss: 0.3725373148918152
training_loss: 0.528939425945282
training_loss: 0.4520317614078522
training_loss: 0.3912544846534729
training_loss: 0.5134069323539734
training_loss: 0.49071645736694336
training_loss: 0.42119795083999634
training_loss: 0.48767754435539246
training_loss: 0.3627379238605499
training_loss: 0.41870659589767456
training_loss: 0.42172038555145264
training_loss: 0.426181823015213
training_loss: 0.39953136444091797
training_loss: 0.42095819115638733
training_loss: 0.4219377636909485
training_loss: 0.3486594557762146
training_loss: 0.407389760017395
training_loss: 0.3816626965999603
training_loss: 0.4274899661540985
training_loss: 0.3882880210876465
training_loss: 0.43417078256607056
training_loss: 0.4541988968849182
training_loss: 0.44467729330062866
training_loss: 0.5234915018081665
training_loss: 0.5130230188369751
training_loss: 0.41032281517982483
training_loss: 0.4477177858352661
training_loss: 0.4832881987094879
training_loss: 0.471805214881897
training_loss: 0.4483160376548767
training_loss: 0.5628021955490112
training_loss: 0.5180041790008545
training_loss: 0.36720597743988037
training_loss: 0.39255961775779724
training_loss: 0.45604202151298523
training_loss: 0.3955434560775757
training_loss: 0.47208911180496216
training_loss: 0.5434592366218567
training_loss: 0.4974278211593628
training_loss: 0.4683440327644348
training_loss: 0.401067852973938
training_loss: 0.4374174475669861
training_loss: 0.5392982363700867
training_loss: 0.42926228046417236
training_loss: 0.43762701749801636
training_loss: 0.38214942812919617
training_loss: 0.48392876982688904
training_loss: 0.4558838903903961
training_loss: 0.40039902925491333
training_loss: 0.44632264971733093
training_loss: 0.43167248368263245
training_loss: 0.376788467168808
training_loss: 0.42759522795677185
training_loss: 0.37986457347869873
training_loss: 0.416883260011673
training_loss: 0.4393216073513031
training_loss: 0.3420829772949219
training_loss: 0.5487352609634399
training_loss: 0.3735552430152893
training_loss: 0.4164716899394989
training_loss: 0.3942561149597168
training_loss: 0.4253891110420227
training_loss: 0.45617130398750305
training_loss: 0.4668712019920349
training_loss: 0.4785618484020233
training_loss: 0.5786616206169128
training_loss: 0.40483787655830383
training_loss: 0.5070770382881165
training_loss: 0.413316547870636
training_loss: 0.4492326080799103
training_loss: 0.41947007179260254
training_loss: 0.529960036277771
training_loss: 0.5426072478294373
training_loss: 0.43180176615715027
training_loss: 0.4542340934276581
training_loss: 0.41255447268486023
training_loss: 0.3949388861656189
training_loss: 0.4165295362472534
training_loss: 0.47558102011680603
training_loss: 0.44558244943618774
training_loss: 0.4274090528488159
training_loss: 0.3831748366355896
training_loss: 0.46378186345100403
training_loss: 0.4193103313446045
training_loss: 0.43908101320266724
training_loss: 0.34002038836479187
validation_loss: 0.39578503370285034
validation_accuracy: 0.84375
validation_loss: 0.4238470792770386
validation_accuracy: 0.8515625
validation_loss: 0.5424932241439819
validation_accuracy: 0.8203125
validation_loss: 0.44642022252082825
validation_accuracy: 0.8359375
validation_loss: 0.4668785333633423
validation_accuracy: 0.83984375
validation_loss: 0.41287854313850403
validation_accuracy: 0.8515625
validation_loss: 0.3993608057498932
validation_accuracy: 0.8828125
validation_loss: 0.4848318099975586
validation_accuracy: 0.8515625
validation_loss: 0.3493407964706421
validation_accuracy: 0.8671875
validation_loss: 0.4816057085990906
validation_accuracy: 0.81640625
validation_loss: 0.46010321378707886
validation_accuracy: 0.8359375
validation_loss: 0.600002110004425
validation_accuracy: 0.7890625
validation_loss: 0.587517261505127
validation_accuracy: 0.79296875
validation_loss: 0.5375763177871704
validation_accuracy: 0.82421875
validation_loss: 0.4633617401123047
validation_accuracy: 0.828125
validation_loss: 0.49681389331817627
validation_accuracy: 0.8359375
validation_loss: 0.46635302901268005
validation_accuracy: 0.83203125
validation_loss: 0.3091743588447571
validation_accuracy: 0.8828125
validation_loss: 0.519790768623352
validation_accuracy: 0.8203125
validation_loss: 0.5514695048332214
validation_accuracy: 0.796875
validation_loss: 0.5330752730369568
validation_accuracy: 0.83203125
validation_loss: 0.5771612524986267
validation_accuracy: 0.8125
validation_loss: 0.4644463062286377
validation_accuracy: 0.8203125
validation_loss: 0.4275263249874115
validation_accuracy: 0.83984375
validation_loss: 0.41487613320350647
validation_accuracy: 0.83984375
validation_loss: 0.5513042211532593
validation_accuracy: 0.8046875
validation_loss: 0.5050694346427917
validation_accuracy: 0.84375
validation_loss: 0.4198710024356842
validation_accuracy: 0.8359375
validation_loss: 0.43269607424736023
validation_accuracy: 0.85546875
validation_loss: 0.400055468082428
validation_accuracy: 0.859375
validation_loss: 0.44277656078338623
validation_accuracy: 0.84375
validation_loss: 0.5054323673248291
validation_accuracy: 0.80078125
validation_loss: 0.4142501950263977
validation_accuracy: 0.84765625
validation_loss: 0.4675658345222473
validation_accuracy: 0.8359375
validation_loss: 0.5342537760734558
validation_accuracy: 0.79296875
validation_loss: 0.4462805390357971
validation_accuracy: 0.84765625
validation_loss: 0.41033077239990234
validation_accuracy: 0.85546875
validation_loss: 0.5196972489356995
validation_accuracy: 0.8046875
validation_loss: 0.39368805289268494
validation_accuracy: 0.875
validation_loss: 0.33386313915252686
validation_accuracy: 0.875
epoch 13/15
training_loss: 0.37460458278656006
training_loss: 0.48645952343940735
training_loss: 0.4894588887691498
training_loss: 0.6107792854309082
training_loss: 0.5019437074661255
training_loss: 0.45650869607925415
training_loss: 0.30916330218315125
training_loss: 0.3530086576938629
training_loss: 0.3793450891971588
training_loss: 0.43276530504226685
training_loss: 0.43628978729248047
training_loss: 0.41595974564552307
training_loss: 0.4626002609729767
training_loss: 0.4636869728565216
training_loss: 0.42687246203422546
training_loss: 0.3589022159576416
training_loss: 0.3320583403110504
training_loss: 0.4663282632827759
training_loss: 0.36328840255737305
training_loss: 0.4575880765914917
training_loss: 0.3501477539539337
training_loss: 0.3797237277030945
training_loss: 0.4890323281288147
training_loss: 0.42705991864204407
training_loss: 0.45270442962646484
training_loss: 0.381501168012619
training_loss: 0.37990573048591614
training_loss: 0.39351746439933777
training_loss: 0.5253796577453613
training_loss: 0.4441332221031189
training_loss: 0.4816475212574005
training_loss: 0.4700331687927246
training_loss: 0.4187390208244324
training_loss: 0.46011650562286377
training_loss: 0.400823175907135
training_loss: 0.42459240555763245
training_loss: 0.4204609990119934
training_loss: 0.42842811346054077
training_loss: 0.40369653701782227
training_loss: 0.38859426975250244
training_loss: 0.43930116295814514
training_loss: 0.3484371304512024
training_loss: 0.44253167510032654
training_loss: 0.3975573182106018
training_loss: 0.40351372957229614
training_loss: 0.38575899600982666
training_loss: 0.4640754461288452
training_loss: 0.5124536752700806
training_loss: 0.5625364184379578
training_loss: 0.4054066836833954
training_loss: 0.47567322850227356
training_loss: 0.5435092449188232
training_loss: 0.5333267450332642
training_loss: 0.4352351725101471
training_loss: 0.4330580234527588
training_loss: 0.39699968695640564
training_loss: 0.47069814801216125
training_loss: 0.321341335773468
training_loss: 0.4250655770301819
training_loss: 0.36059749126434326
training_loss: 0.47993582487106323
training_loss: 0.45067304372787476
training_loss: 0.5384060144424438
training_loss: 0.42373085021972656
training_loss: 0.4215454161167145
training_loss: 0.4875856339931488
training_loss: 0.345847487449646
training_loss: 0.3923148214817047
training_loss: 0.44712957739830017
training_loss: 0.3937200605869293
training_loss: 0.42004865407943726
training_loss: 0.37307652831077576
training_loss: 0.5134194493293762
training_loss: 0.5006936192512512
training_loss: 0.32778671383857727
training_loss: 0.4048214852809906
training_loss: 0.36209598183631897
training_loss: 0.31281960010528564
training_loss: 0.45265164971351624
training_loss: 0.48842403292655945
training_loss: 0.4715839922428131
training_loss: 0.40607598423957825
training_loss: 0.399951696395874
training_loss: 0.4501396715641022
training_loss: 0.3691480755805969
training_loss: 0.41680485010147095
training_loss: 0.4325936436653137
training_loss: 0.561109721660614
training_loss: 0.42161568999290466
training_loss: 0.3833979070186615
training_loss: 0.4277149438858032
training_loss: 0.3846680819988251
training_loss: 0.5265379548072815
training_loss: 0.40722933411598206
training_loss: 0.41638246178627014
training_loss: 0.6207618713378906
training_loss: 0.5628077983856201
training_loss: 0.3892506957054138
training_loss: 0.443750262260437
training_loss: 0.42518988251686096
training_loss: 0.5029835104942322
training_loss: 0.37512680888175964
training_loss: 0.5075566172599792
training_loss: 0.408732533454895
training_loss: 0.5097582340240479
training_loss: 0.454549640417099
training_loss: 0.38484588265419006
training_loss: 0.3286949396133423
training_loss: 0.3912031948566437
training_loss: 0.4733840525150299
training_loss: 0.457240492105484
training_loss: 0.3738582134246826
training_loss: 0.41250231862068176
training_loss: 0.3914249837398529
training_loss: 0.39254435896873474
training_loss: 0.4132605791091919
training_loss: 0.37560582160949707
training_loss: 0.4720529317855835
training_loss: 0.468533992767334
training_loss: 0.4444224238395691
training_loss: 0.3694349229335785
training_loss: 0.3916047215461731
training_loss: 0.4227662980556488
training_loss: 0.49234503507614136
training_loss: 0.40702396631240845
training_loss: 0.3566281199455261
training_loss: 0.3951576352119446
training_loss: 0.4283711612224579
training_loss: 0.42345499992370605
training_loss: 0.36527225375175476
training_loss: 0.40503984689712524
training_loss: 0.4868139624595642
training_loss: 0.4529990255832672
training_loss: 0.39015164971351624
training_loss: 0.46476900577545166
training_loss: 0.48784637451171875
training_loss: 0.5007787942886353
training_loss: 0.42037224769592285
training_loss: 0.4427710473537445
training_loss: 0.4368821382522583
training_loss: 0.46706652641296387
training_loss: 0.46931830048561096
training_loss: 0.4063175320625305
training_loss: 0.48257601261138916
training_loss: 0.3982393741607666
training_loss: 0.5370937585830688
training_loss: 0.41817915439605713
training_loss: 0.3934406042098999
training_loss: 0.4236144423484802
training_loss: 0.43638521432876587
training_loss: 0.4369388222694397
training_loss: 0.439083993434906
training_loss: 0.45211556553840637
training_loss: 0.41328543424606323
training_loss: 0.3517530858516693
training_loss: 0.49729299545288086
training_loss: 0.4846031665802002
training_loss: 0.42760515213012695
training_loss: 0.43078503012657166
training_loss: 0.40995994210243225
training_loss: 0.3937160074710846
training_loss: 0.5028109550476074
training_loss: 0.3831201195716858
training_loss: 0.3958209753036499
training_loss: 0.4302663803100586
training_loss: 0.3730924427509308
training_loss: 0.44036436080932617
training_loss: 0.5748719573020935
training_loss: 0.3033905327320099
training_loss: 0.4612431228160858
training_loss: 0.40465018153190613
training_loss: 0.4179954528808594
training_loss: 0.5229928493499756
training_loss: 0.398183137178421
training_loss: 0.48237013816833496
training_loss: 0.31983745098114014
training_loss: 0.47154518961906433
training_loss: 0.3895256221294403
training_loss: 0.42311909794807434
training_loss: 0.41107916831970215
training_loss: 0.5288906693458557
training_loss: 0.3699306845664978
training_loss: 0.48069295287132263
training_loss: 0.3902505338191986
training_loss: 0.44140392541885376
training_loss: 0.37811553478240967
training_loss: 0.45626381039619446
training_loss: 0.42237627506256104
training_loss: 0.49407845735549927
training_loss: 0.4769899845123291
training_loss: 0.40142151713371277
training_loss: 0.45002102851867676
training_loss: 0.47442716360092163
training_loss: 0.37076422572135925
training_loss: 0.4420492351055145
training_loss: 0.42202529311180115
training_loss: 0.4316426217556
training_loss: 0.567355751991272
training_loss: 0.45175063610076904
training_loss: 0.3753211200237274
training_loss: 0.41047435998916626
training_loss: 0.44092339277267456
training_loss: 0.3763795495033264
training_loss: 0.4360697865486145
training_loss: 0.5382018685340881
training_loss: 0.41110506653785706
training_loss: 0.47501155734062195
training_loss: 0.4348902702331543
training_loss: 0.43510687351226807
training_loss: 0.4928991198539734
training_loss: 0.4890386164188385
training_loss: 0.37404346466064453
training_loss: 0.5269390344619751
training_loss: 0.4720335006713867
training_loss: 0.4533247947692871
training_loss: 0.38301554322242737
training_loss: 0.39944857358932495
training_loss: 0.4658472537994385
training_loss: 0.3919806182384491
training_loss: 0.4947437345981598
training_loss: 0.4581170082092285
training_loss: 0.40780261158943176
training_loss: 0.3884815275669098
training_loss: 0.5049108266830444
training_loss: 0.3758934438228607
training_loss: 0.46501338481903076
training_loss: 0.5202269554138184
training_loss: 0.4822613000869751
training_loss: 0.3690428137779236
training_loss: 0.37010568380355835
training_loss: 0.45394593477249146
training_loss: 0.36815720796585083
training_loss: 0.36067086458206177
training_loss: 0.4225141108036041
training_loss: 0.531684935092926
validation_loss: 0.41691747307777405
validation_accuracy: 0.8515625
validation_loss: 0.4486026167869568
validation_accuracy: 0.8359375
validation_loss: 0.5495241284370422
validation_accuracy: 0.828125
validation_loss: 0.4649324417114258
validation_accuracy: 0.8203125
validation_loss: 0.4775489866733551
validation_accuracy: 0.81640625
validation_loss: 0.4269818961620331
validation_accuracy: 0.84375
validation_loss: 0.39813220500946045
validation_accuracy: 0.87109375
validation_loss: 0.48769068717956543
validation_accuracy: 0.84765625
validation_loss: 0.36250048875808716
validation_accuracy: 0.8671875
validation_loss: 0.5053201913833618
validation_accuracy: 0.8125
validation_loss: 0.47150546312332153
validation_accuracy: 0.82421875
validation_loss: 0.6022886633872986
validation_accuracy: 0.7734375
validation_loss: 0.5949335098266602
validation_accuracy: 0.79296875
validation_loss: 0.52948397397995
validation_accuracy: 0.84375
validation_loss: 0.4677511155605316
validation_accuracy: 0.8359375
validation_loss: 0.5079646110534668
validation_accuracy: 0.8203125
validation_loss: 0.4618512690067291
validation_accuracy: 0.81640625
validation_loss: 0.3360814154148102
validation_accuracy: 0.87109375
validation_loss: 0.5191422700881958
validation_accuracy: 0.81640625
validation_loss: 0.5776978135108948
validation_accuracy: 0.8203125
validation_loss: 0.5516851544380188
validation_accuracy: 0.8203125
validation_loss: 0.5879397392272949
validation_accuracy: 0.81640625
validation_loss: 0.45819103717803955
validation_accuracy: 0.828125
validation_loss: 0.43208837509155273
validation_accuracy: 0.8359375
validation_loss: 0.42687201499938965
validation_accuracy: 0.83203125
validation_loss: 0.5690115690231323
validation_accuracy: 0.8046875
validation_loss: 0.5112940073013306
validation_accuracy: 0.84375
validation_loss: 0.42493224143981934
validation_accuracy: 0.81640625
validation_loss: 0.43810564279556274
validation_accuracy: 0.84375
validation_loss: 0.4135007858276367
validation_accuracy: 0.84375
validation_loss: 0.4444403648376465
validation_accuracy: 0.83203125
validation_loss: 0.513577938079834
validation_accuracy: 0.81640625
validation_loss: 0.41723158955574036
validation_accuracy: 0.84375
validation_loss: 0.4867820143699646
validation_accuracy: 0.84765625
validation_loss: 0.5401586890220642
validation_accuracy: 0.7890625
validation_loss: 0.4424951672554016
validation_accuracy: 0.8515625
validation_loss: 0.42825478315353394
validation_accuracy: 0.8359375
validation_loss: 0.5162689089775085
validation_accuracy: 0.8125
validation_loss: 0.40489262342453003
validation_accuracy: 0.8671875
validation_loss: 0.3360871970653534
validation_accuracy: 0.875
epoch 14/15
training_loss: 0.41705524921417236
training_loss: 0.4473276138305664
training_loss: 0.4194334149360657
training_loss: 0.35434192419052124
training_loss: 0.5093146562576294
training_loss: 0.4827333092689514
training_loss: 0.48417335748672485
training_loss: 0.4606333374977112
training_loss: 0.3429596424102783
training_loss: 0.37279975414276123
training_loss: 0.43263816833496094
training_loss: 0.5753625631332397
training_loss: 0.42248281836509705
training_loss: 0.3623904883861542
training_loss: 0.5284954905509949
training_loss: 0.4517352283000946
training_loss: 0.46282604336738586
training_loss: 0.3622782826423645
training_loss: 0.39765942096710205
training_loss: 0.41178005933761597
training_loss: 0.4094339907169342
training_loss: 0.4776473641395569
training_loss: 0.41513341665267944
training_loss: 0.3850255608558655
training_loss: 0.492910236120224
training_loss: 0.3721456825733185
training_loss: 0.5554543733596802
training_loss: 0.4891272485256195
training_loss: 0.4276171922683716
training_loss: 0.4651426076889038
training_loss: 0.4303315281867981
training_loss: 0.47455036640167236
training_loss: 0.44272226095199585
training_loss: 0.3751775026321411
training_loss: 0.4093642830848694
training_loss: 0.40349116921424866
training_loss: 0.33129701018333435
training_loss: 0.4448626637458801
training_loss: 0.5348242521286011
training_loss: 0.5337722301483154
training_loss: 0.4205819070339203
training_loss: 0.4779609739780426
training_loss: 0.4516925811767578
training_loss: 0.35768991708755493
training_loss: 0.3861601650714874
training_loss: 0.4503559172153473
training_loss: 0.4486059546470642
training_loss: 0.38941916823387146
training_loss: 0.420614629983902
training_loss: 0.5190408825874329
training_loss: 0.458662748336792
training_loss: 0.3738998472690582
training_loss: 0.38622719049453735
training_loss: 0.4961651563644409
training_loss: 0.44897323846817017
training_loss: 0.3732083737850189
training_loss: 0.4850228428840637
training_loss: 0.40363895893096924
training_loss: 0.3829209506511688
training_loss: 0.5143105983734131
training_loss: 0.40331149101257324
training_loss: 0.44284600019454956
training_loss: 0.4031561613082886
training_loss: 0.3662426173686981
training_loss: 0.4971503019332886
training_loss: 0.38898226618766785
training_loss: 0.34247565269470215
training_loss: 0.4654928743839264
training_loss: 0.38055315613746643
training_loss: 0.4536944627761841
training_loss: 0.42849820852279663
training_loss: 0.4690670967102051
training_loss: 0.4434070885181427
training_loss: 0.45500612258911133
training_loss: 0.41179850697517395
training_loss: 0.4420885443687439
training_loss: 0.46648213267326355
training_loss: 0.46911686658859253
training_loss: 0.45731788873672485
training_loss: 0.39583107829093933
training_loss: 0.3907235562801361
training_loss: 0.45215076208114624
training_loss: 0.35552629828453064
training_loss: 0.41178375482559204
training_loss: 0.4637421667575836
training_loss: 0.40134531259536743
training_loss: 0.3305404782295227
training_loss: 0.3983498811721802
training_loss: 0.41127073764801025
training_loss: 0.4834001660346985
training_loss: 0.45257723331451416
training_loss: 0.4158186614513397
training_loss: 0.33137184381484985
training_loss: 0.4023628830909729
training_loss: 0.4638213515281677
training_loss: 0.39143484830856323
training_loss: 0.3783261775970459
training_loss: 0.48903608322143555
training_loss: 0.3891177177429199
training_loss: 0.3998834192752838
training_loss: 0.3709089756011963
training_loss: 0.4168473780155182
training_loss: 0.36268627643585205
training_loss: 0.49505123496055603
training_loss: 0.450456827878952
training_loss: 0.3992800712585449
training_loss: 0.40928345918655396
training_loss: 0.40371042490005493
training_loss: 0.4578324556350708
training_loss: 0.49946731328964233
training_loss: 0.5891802906990051
training_loss: 0.36136674880981445
training_loss: 0.5118599534034729
training_loss: 0.4302089214324951
training_loss: 0.42492783069610596
training_loss: 0.4182443618774414
training_loss: 0.43801453709602356
training_loss: 0.4147418141365051
training_loss: 0.41285184025764465
training_loss: 0.5067858099937439
training_loss: 0.5326316952705383
training_loss: 0.41908949613571167
training_loss: 0.40756407380104065
training_loss: 0.43400317430496216
training_loss: 0.6224165558815002
training_loss: 0.4126173257827759
training_loss: 0.32938089966773987
training_loss: 0.4488762617111206
training_loss: 0.39660751819610596
training_loss: 0.3775344789028168
training_loss: 0.43916377425193787
training_loss: 0.4661281704902649
training_loss: 0.4231300354003906
training_loss: 0.37974032759666443
training_loss: 0.39123815298080444
training_loss: 0.41021206974983215
training_loss: 0.5273171067237854
training_loss: 0.4825144112110138
training_loss: 0.42420339584350586
training_loss: 0.46356117725372314
training_loss: 0.3633747696876526
training_loss: 0.5072759389877319
training_loss: 0.39010876417160034
training_loss: 0.46459347009658813
training_loss: 0.4277963936328888
training_loss: 0.47293880581855774
training_loss: 0.495930552482605
training_loss: 0.4196890890598297
training_loss: 0.4392862319946289
training_loss: 0.3436218202114105
training_loss: 0.43595176935195923
training_loss: 0.42084208130836487
training_loss: 0.45440778136253357
training_loss: 0.4532076120376587
training_loss: 0.38383907079696655
training_loss: 0.3424188494682312
training_loss: 0.40700215101242065
training_loss: 0.4447776973247528
training_loss: 0.3621593713760376
training_loss: 0.40274685621261597
training_loss: 0.4555213451385498
training_loss: 0.3837999701499939
training_loss: 0.4059831500053406
training_loss: 0.3570977449417114
training_loss: 0.4643644690513611
training_loss: 0.3630392253398895
training_loss: 0.3789694607257843
training_loss: 0.45409753918647766
training_loss: 0.404800683259964
training_loss: 0.40012311935424805
training_loss: 0.37754836678504944
training_loss: 0.48714494705200195
training_loss: 0.3997346758842468
training_loss: 0.4830998182296753
training_loss: 0.3912673592567444
training_loss: 0.3750002384185791
training_loss: 0.3850646913051605
training_loss: 0.39918583631515503
training_loss: 0.3923579156398773
training_loss: 0.46386992931365967
training_loss: 0.40408164262771606
training_loss: 0.3874672055244446
training_loss: 0.44419029355049133
training_loss: 0.45164942741394043
training_loss: 0.38021963834762573
training_loss: 0.2979549765586853
training_loss: 0.43745747208595276
training_loss: 0.45596855878829956
training_loss: 0.4659251570701599
training_loss: 0.4117080569267273
training_loss: 0.4202525317668915
training_loss: 0.41853708028793335
training_loss: 0.4280495345592499
training_loss: 0.45933571457862854
training_loss: 0.5140593647956848
training_loss: 0.5074073076248169
training_loss: 0.4240555763244629
training_loss: 0.3978729844093323
training_loss: 0.47762244939804077
training_loss: 0.3966865837574005
training_loss: 0.4869428873062134
training_loss: 0.3855310380458832
training_loss: 0.41638872027397156
training_loss: 0.4174349308013916
training_loss: 0.5011289119720459
training_loss: 0.3885032534599304
training_loss: 0.5161570906639099
training_loss: 0.4643862247467041
training_loss: 0.39305394887924194
training_loss: 0.4704428017139435
training_loss: 0.44223034381866455
training_loss: 0.4622463583946228
training_loss: 0.3514043092727661
training_loss: 0.5052855014801025
training_loss: 0.4216141402721405
training_loss: 0.5341777801513672
training_loss: 0.5488569736480713
training_loss: 0.41967859864234924
training_loss: 0.43135905265808105
training_loss: 0.3998153805732727
training_loss: 0.42268386483192444
training_loss: 0.3665403127670288
training_loss: 0.423094242811203
training_loss: 0.3892443776130676
training_loss: 0.3420168161392212
training_loss: 0.4555346369743347
training_loss: 0.6257859468460083
training_loss: 0.3503141403198242
training_loss: 0.49272966384887695
training_loss: 0.3562965393066406
training_loss: 0.4487490653991699
training_loss: 0.3922789990901947
training_loss: 0.4631601572036743
training_loss: 0.3480883240699768
training_loss: 0.4276374578475952
validation_loss: 0.39687174558639526
validation_accuracy: 0.875
validation_loss: 0.41040897369384766
validation_accuracy: 0.85546875
validation_loss: 0.566659152507782
validation_accuracy: 0.79296875
validation_loss: 0.43476104736328125
validation_accuracy: 0.84375
validation_loss: 0.47618213295936584
validation_accuracy: 0.84375
validation_loss: 0.42006775736808777
validation_accuracy: 0.8359375
validation_loss: 0.42281579971313477
validation_accuracy: 0.875
validation_loss: 0.48157379031181335
validation_accuracy: 0.85546875
validation_loss: 0.3493083417415619
validation_accuracy: 0.86328125
validation_loss: 0.49838730692863464
validation_accuracy: 0.81640625
validation_loss: 0.4488256573677063
validation_accuracy: 0.84765625
validation_loss: 0.6395907998085022
validation_accuracy: 0.78515625
validation_loss: 0.5813307762145996
validation_accuracy: 0.80078125
validation_loss: 0.5460569262504578
validation_accuracy: 0.80859375
validation_loss: 0.4721295237541199
validation_accuracy: 0.84765625
validation_loss: 0.5071602463722229
validation_accuracy: 0.83203125
validation_loss: 0.4864593744277954
validation_accuracy: 0.8359375
validation_loss: 0.3136308193206787
validation_accuracy: 0.90625
validation_loss: 0.542898416519165
validation_accuracy: 0.80859375
validation_loss: 0.561148464679718
validation_accuracy: 0.8203125
validation_loss: 0.5250387191772461
validation_accuracy: 0.83984375
validation_loss: 0.6042829751968384
validation_accuracy: 0.796875
validation_loss: 0.4968487024307251
validation_accuracy: 0.8125
validation_loss: 0.4550260007381439
validation_accuracy: 0.8203125
validation_loss: 0.43248438835144043
validation_accuracy: 0.84765625
validation_loss: 0.5722968578338623
validation_accuracy: 0.78515625
validation_loss: 0.4850497543811798
validation_accuracy: 0.84375
validation_loss: 0.46164336800575256
validation_accuracy: 0.796875
validation_loss: 0.4623109698295593
validation_accuracy: 0.84765625
validation_loss: 0.3919171690940857
validation_accuracy: 0.859375
validation_loss: 0.467385470867157
validation_accuracy: 0.82421875
validation_loss: 0.518135666847229
validation_accuracy: 0.796875
validation_loss: 0.43136167526245117
validation_accuracy: 0.859375
validation_loss: 0.4550023674964905
validation_accuracy: 0.8359375
validation_loss: 0.5560615062713623
validation_accuracy: 0.796875
validation_loss: 0.47995612025260925
validation_accuracy: 0.84765625
validation_loss: 0.4380969703197479
validation_accuracy: 0.82421875
validation_loss: 0.5361903309822083
validation_accuracy: 0.83203125
validation_loss: 0.40290337800979614
validation_accuracy: 0.875
validation_loss: 0.33691179752349854
validation_accuracy: 0.9375